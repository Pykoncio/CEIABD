{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd92627-75f7-4bb1-9bdc-d7c4c630604c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cargando un archivos de datos a un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ca8b1f1-ff7b-43b7-b624-5d102a05e430",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+-------+\n|      Date|Time|City|Item|Total|Payment|\n+----------+----+----+----+-----+-------+\n|2012-01-01|null|null|null| null|   null|\n|2012-01-01|null|null|null| null|   null|\n|2012-01-01|null|null|null| null|   null|\n|2012-01-01|null|null|null| null|   null|\n+----------+----+----+----+-----+-------+\nonly showing top 4 rows\n\n"
     ]
    }
   ],
   "source": [
    "#importar módulos\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "#crear sesión para poder acceder a todas las API de Spark\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Introducción a Spark DataFrame\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "\n",
    "#define el data schema del archivo que queremos leer\n",
    "purchaseSchema = StructType([\n",
    "    StructField(\"Date\", DateType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Item\", StringType(), True),\n",
    "    StructField(\"Total\", FloatType(), True),\n",
    "    StructField(\"Payment\", StringType(), True),\n",
    "])    \n",
    "\n",
    "# lee el archivo csv (con el data schema definido) en un dataframe de Spark. Usa el delimitador \"tab\" \n",
    "\n",
    "purchaseDataframe = spark.read.csv(\n",
    "    \"/FileStore/tables/purchases-3.csv\", \n",
    "    header=True, schema=purchaseSchema, sep=\"\\t\")\n",
    "\n",
    "#Muestra 3 filas de nuestro Dataframe\n",
    "purchaseDataframe.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fb5227f-7037-4e30-8664-306f8abe6fc8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Contamos el número de filas, luego imprimimos el dataframe schema y las estadísticas de nuestra data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af087ec9-6520-44e9-b01c-b7b506e19060",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cuenta el número de filas de nuestra dataframe\n",
    "num_rows = purchaseDataframe.count()\n",
    "print(\"number of rows: \", num_rows)\n",
    "\n",
    "#Muestra el dataframe schema\n",
    "purchaseDataframe.printSchema()\n",
    "\n",
    "#Muestra estadísticas del campo que elegimos \"Total\" \n",
    "purchaseDataframe.describe('Total').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57a460fd-b00f-42de-92f0-9924c01ccb46",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creamos un nuevo dataframe como subconjunto del dataframe que cargamos inicialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1102829d-2968-41ae-ab54-c27a206f0e15",
     "showTitle": false,
     "title": ""
    },
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Crea un nuevo dataframe con las columnas \"City\" y \"Total\"\n",
    "newDataframe = purchaseDataframe.select(purchaseDataframe['City'], \n",
    "                                              purchaseDataframe['Total'])\n",
    "\n",
    "newDataframe.show(5); #Muestra las 3 primeras filas\n",
    "newDataframe.printSchema() #Muestra el dataset schema del nuuevo dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cf4ffdc-7349-4d3e-89dc-5445dd1318ab",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sumando un valor constante a todas las filas de una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7cb4e5f-58a0-414e-b079-ada26eb40409",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Sumando un valor constante de 10 a todas las filas de la columna \"Total\"\n",
    "purchaseDataframe.select(purchaseDataframe['City'],purchaseDataframe['Total'],\n",
    "                         purchaseDataframe['Total']+10).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab233281-fc77-44ee-9277-920ef694a136",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Uso de filtros en un dataframe usando una condición definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aee87d59-7c8c-4cca-9412-c62a498e7ca9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Filtra solo las filas cuyo valor de la columna \"Total\" sea mayor a 200\n",
    "purchaseDataframe.filter(purchaseDataframe['Total'] > 200).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49802db1-e81a-43e0-9ff7-da95f40fd90a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Ordenando un dataframe por una columna definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb201b37-d61b-4e91-8bb9-920ecad25fb5",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ordena el dataframe por la columna \"City\"\n",
    "sortedByCity = purchaseDataframe.orderBy('City').show(5)\n",
    "sortedByCity = purchaseDataframe.orderBy('City', 'Total').show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f43d07f1-7518-412d-af8a-79d72791d15f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Usando consultas SQL en un dataFrame\n",
    "\n",
    "Crear un nuevo dataFrame a partir del subconjunto de nuestro dataFrame existente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2057799b-03fd-4975-a52d-f04fe0938611",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Vamos a crear una vista temporal a partir de nuestro dataframe inicial\n",
    "purchaseDataframe.createOrReplaceTempView(\"purchaseSql\")\n",
    "\n",
    "#Selecciona las columnas \"Total\" y \"Payment\" de la vista recientemente creada\n",
    "anotherNewDataframe = spark.sql(\"SELECT Total, Payment FROM purchaseSql\")\n",
    "anotherNewDataframe.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab5e66ca-5267-47f3-a266-faf771066638",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Ordenando los datos a partir de una columna definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ec515e3-0620-46bd-a608-994ca539c32c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ordenando los datos por la columna \"City\"\n",
    "orderByCity = spark.sql(\"SELECT * FROM purchaseSql ORDER BY City\")\n",
    "orderByCity.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55d510da-6f27-4ff0-8b5c-664bbfd3085f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Filtraremos la columna \"Total\" para valores mayores a 200 y lo ordenaremos por la columna \"Payment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8293d5d0-de6e-4fd2-84db-7be2273bca58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ""
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filterAndSortWithSQL = spark.sql(\"SELECT * FROM purchaseSql WHERE Total>200 ORDER BY Payment\")\n",
    "filterAndSortWithSQL.show(10)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DataFrames y Spark SQL",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "name": "02 Introduccion a DataFrame y Spark SQL",
  "notebookId": 2460219875128113
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
