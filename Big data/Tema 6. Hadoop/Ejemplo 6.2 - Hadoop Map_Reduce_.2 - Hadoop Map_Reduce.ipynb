{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11whFYYd9S4aVm-Hcwkv9JZ2F-rh9k27P","timestamp":1705948734324},{"file_id":"1M4VG_YF7_RL5nhPNuGaQcZqKC6yhVYSK","timestamp":1633598230343}],"collapsed_sections":["j9bT9M1yvyXG","fVfN-Tl2BjHN"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"j9bT9M1yvyXG"},"source":["## Paso 1: Instalación de Hadoop en el entorno"]},{"cell_type":"code","metadata":{"id":"bijZAdD_cBMK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705962684321,"user_tz":-60,"elapsed":30418,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"4bdf383f-1c73-48ec-ce17-3ae4a5781ec8"},"source":["!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-22 22:30:53--  https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n","Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n","Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 730107476 (696M) [application/x-gzip]\n","Saving to: ‘hadoop-3.3.6.tar.gz’\n","\n","hadoop-3.3.6.tar.gz 100%[===================>] 696.28M  25.7MB/s    in 30s     \n","\n","2024-01-22 22:31:24 (23.3 MB/s) - ‘hadoop-3.3.6.tar.gz’ saved [730107476/730107476]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"Mj40txsTw6DZ"},"source":["Descompresión de la distribución de hadoop"]},{"cell_type":"code","metadata":{"id":"nVce513-cBHm","executionInfo":{"status":"ok","timestamp":1705962700792,"user_tz":-60,"elapsed":16476,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}}},"source":["!tar -xzf hadoop-3.3.6.tar.gz"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JrOYu40BZDn"},"source":["Copiar a /usr/local"]},{"cell_type":"code","metadata":{"id":"JF-ze-YOdync","executionInfo":{"status":"ok","timestamp":1705962713282,"user_tz":-60,"elapsed":12508,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}}},"source":["#copy  hadoop file to user/local\n","!cp -r hadoop-3.3.6/ /usr/local/"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fVfN-Tl2BjHN"},"source":["## Step 2: Configurar el Hadoop JAVA HOME\n","\n","Hadoop requiere que se establezca la ruta de acceso a Java, ya sea como una variable de entorno o en el archivo de configuración de Hadoop."]},{"cell_type":"markdown","metadata":{"id":"GowOFc6zxqbC"},"source":["1. Buscamos cual es la dirección de Java en la máquina Google Colab"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KeNlCJDsBjHO","executionInfo":{"status":"ok","timestamp":1705962713283,"user_tz":-60,"elapsed":6,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"dc278371-7a65-4c27-82fa-29b05cebfd02"},"source":["!readlink -f /usr/bin/java | sed \"s:bin/java::\""],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/lib/jvm/java-11-openjdk-amd64/\n"]}]},{"cell_type":"markdown","metadata":{"id":"E108Qq9dBjHP"},"source":["2. Establecemos mediante código Python el valor de esta variable\n","\n"]},{"cell_type":"code","metadata":{"id":"vsWEEcqfpQWY","executionInfo":{"status":"ok","timestamp":1705962713283,"user_tz":-60,"elapsed":3,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}}},"source":["import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\""],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oj00rPPZyEWZ"},"source":["# Paso 3:  Ejecutando Hadoop"]},{"cell_type":"code","metadata":{"id":"Zhf-zK7NcBDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705962713811,"user_tz":-60,"elapsed":531,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"c76f6551-6698-42ed-f5dd-0740e5a91dfc"},"source":["#Running Hadoop\n","!/usr/local/hadoop-3.3.6/bin/hadoop"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\n"," or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\n","  where CLASSNAME is a user-provided Java class\n","\n","  OPTIONS is none or any of:\n","\n","buildpaths                       attempt to add class files from build tree\n","--config dir                     Hadoop config directory\n","--debug                          turn on shell script debug mode\n","--help                           usage information\n","hostnames list[,of,host,names]   hosts to use in worker mode\n","hosts filename                   list of hosts to use in worker mode\n","loglevel level                   set the log4j level for this command\n","workers                          turn on worker mode\n","\n","  SUBCOMMAND is one of:\n","\n","\n","    Admin Commands:\n","\n","daemonlog     get/set the log level for each daemon\n","\n","    Client Commands:\n","\n","archive       create a Hadoop archive\n","checknative   check native Hadoop and compression libraries availability\n","classpath     prints the class path needed to get the Hadoop jar and the required libraries\n","conftest      validate configuration XML files\n","credential    interact with credential providers\n","distch        distributed metadata changer\n","distcp        copy file or directories recursively\n","dtutil        operations related to delegation tokens\n","envvars       display computed Hadoop environment variables\n","fs            run a generic filesystem user client\n","gridmix       submit a mix of synthetic job, modeling a profiled from production load\n","jar <jar>     run a jar file. NOTE: please use \"yarn jar\" to launch YARN applications, not this\n","              command.\n","jnipath       prints the java.library.path\n","kdiag         Diagnose Kerberos Problems\n","kerbname      show auth_to_local principal conversion\n","key           manage keys via the KeyProvider\n","rumenfolder   scale a rumen input trace\n","rumentrace    convert logs into a rumen trace\n","s3guard       S3 Commands\n","trace         view and modify Hadoop tracing settings\n","version       print the version\n","\n","    Daemon Commands:\n","\n","kms           run KMS, the Key Management Server\n","registrydns   run the registry DNS server\n","\n","SUBCOMMAND may print help when invoked w/o parameters or with -h.\n"]}]},{"cell_type":"code","metadata":{"id":"uI-YBPIzcBCA","executionInfo":{"status":"ok","timestamp":1705962714353,"user_tz":-60,"elapsed":543,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}}},"source":["!mkdir ~/input\n","!cp /usr/local/hadoop-3.3.6/etc/hadoop/*.xml ~/input"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"6DuDJIsPcA98","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705962714353,"user_tz":-60,"elapsed":4,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"e6df4baf-686b-4b4d-a86b-d8f4bb98d305"},"source":["!ls ~/input"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["capacity-scheduler.xml\thadoop-policy.xml  hdfs-site.xml    kms-acls.xml  mapred-site.xml\n","core-site.xml\t\thdfs-rbf-site.xml  httpfs-site.xml  kms-site.xml  yarn-site.xml\n"]}]},{"cell_type":"code","metadata":{"id":"RZi5zOGKyySH","executionInfo":{"status":"ok","timestamp":1705962724112,"user_tz":-60,"elapsed":9761,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"3888b707-52bd-4861-d365-aae2d40e486f","colab":{"base_uri":"https://localhost:8080/"}},"source":["!/usr/local/hadoop-3.3.6/bin/hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar grep ~/input ~/grep_example 'allowed[.]*'"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-22 22:31:58,257 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-01-22 22:31:58,782 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-01-22 22:31:58,782 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","2024-01-22 22:31:59,335 INFO input.FileInputFormat: Total input files to process : 10\n","2024-01-22 22:31:59,456 INFO mapreduce.JobSubmitter: number of splits:10\n","2024-01-22 22:31:59,911 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2117545184_0001\n","2024-01-22 22:31:59,912 INFO mapreduce.JobSubmitter: Executing with tokens: []\n","2024-01-22 22:32:00,269 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n","2024-01-22 22:32:00,270 INFO mapreduce.Job: Running job: job_local2117545184_0001\n","2024-01-22 22:32:00,281 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n","2024-01-22 22:32:00,291 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:00,293 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:00,293 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:00,299 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n","2024-01-22 22:32:00,388 INFO mapred.LocalJobRunner: Waiting for map tasks\n","2024-01-22 22:32:00,390 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000000_0\n","2024-01-22 22:32:00,438 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:00,442 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:00,442 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:00,483 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:00,491 INFO mapred.MapTask: Processing split: file:/root/input/hadoop-policy.xml:0+11765\n","2024-01-22 22:32:00,643 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:00,643 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:00,643 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:00,643 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:00,643 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:00,650 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:00,689 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:00,691 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:00,691 INFO mapred.MapTask: Spilling map output\n","2024-01-22 22:32:00,691 INFO mapred.MapTask: bufstart = 0; bufend = 374; bufvoid = 104857600\n","2024-01-22 22:32:00,691 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600\n","2024-01-22 22:32:00,730 INFO mapred.MapTask: Finished spill 0\n","2024-01-22 22:32:00,750 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000000_0 is done. And is in the process of committing\n","2024-01-22 22:32:00,756 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:00,756 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000000_0' done.\n","2024-01-22 22:32:00,767 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000000_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=294292\n","\t\tFILE: Number of bytes written=921591\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=275\n","\t\tMap output records=22\n","\t\tMap output bytes=374\n","\t\tMap output materialized bytes=25\n","\t\tInput split bytes=99\n","\t\tCombine input records=22\n","\t\tCombine output records=1\n","\t\tSpilled Records=1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=313524224\n","\tFile Input Format Counters \n","\t\tBytes Read=11765\n","2024-01-22 22:32:00,768 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000000_0\n","2024-01-22 22:32:00,769 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000001_0\n","2024-01-22 22:32:00,771 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:00,771 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:00,771 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:00,772 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:00,778 INFO mapred.MapTask: Processing split: file:/root/input/capacity-scheduler.xml:0+9213\n","2024-01-22 22:32:00,858 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:00,858 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:00,858 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:00,858 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:00,858 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:00,860 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:00,876 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:00,882 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:00,882 INFO mapred.MapTask: Spilling map output\n","2024-01-22 22:32:00,882 INFO mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600\n","2024-01-22 22:32:00,882 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n","2024-01-22 22:32:00,901 INFO mapred.MapTask: Finished spill 0\n","2024-01-22 22:32:00,906 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000001_0 is done. And is in the process of committing\n","2024-01-22 22:32:00,908 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:00,910 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000001_0' done.\n","2024-01-22 22:32:00,911 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000001_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=304497\n","\t\tFILE: Number of bytes written=921647\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=244\n","\t\tMap output records=1\n","\t\tMap output bytes=16\n","\t\tMap output materialized bytes=24\n","\t\tInput split bytes=104\n","\t\tCombine input records=1\n","\t\tCombine output records=1\n","\t\tSpilled Records=1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=24\n","\t\tTotal committed heap usage (bytes)=313524224\n","\tFile Input Format Counters \n","\t\tBytes Read=9213\n","2024-01-22 22:32:00,911 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000001_0\n","2024-01-22 22:32:00,912 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000002_0\n","2024-01-22 22:32:00,913 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:00,913 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:00,914 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:00,914 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:00,917 INFO mapred.MapTask: Processing split: file:/root/input/kms-acls.xml:0+3518\n","2024-01-22 22:32:00,959 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:00,959 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:00,959 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:00,959 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:00,959 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:00,961 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:00,967 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:00,968 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:00,998 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000002_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,005 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,008 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000002_0' done.\n","2024-01-22 22:32:01,009 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000002_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=309007\n","\t\tFILE: Number of bytes written=921685\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=135\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=94\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=11\n","\t\tTotal committed heap usage (bytes)=313524224\n","\tFile Input Format Counters \n","\t\tBytes Read=3518\n","2024-01-22 22:32:01,016 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000002_0\n","2024-01-22 22:32:01,017 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000003_0\n","2024-01-22 22:32:01,021 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,022 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,022 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,022 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,028 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-site.xml:0+775\n","2024-01-22 22:32:01,102 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,102 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,102 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,103 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,103 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,104 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,111 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,112 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,118 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000003_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,121 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,121 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000003_0' done.\n","2024-01-22 22:32:01,122 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000003_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=310774\n","\t\tFILE: Number of bytes written=921723\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=21\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=95\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=14\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=775\n","2024-01-22 22:32:01,123 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000003_0\n","2024-01-22 22:32:01,124 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000004_0\n","2024-01-22 22:32:01,126 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,126 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,126 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,126 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,139 INFO mapred.MapTask: Processing split: file:/root/input/core-site.xml:0+774\n","2024-01-22 22:32:01,222 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,223 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,225 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,225 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,226 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,227 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,233 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,233 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,238 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000004_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,241 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,241 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000004_0' done.\n","2024-01-22 22:32:01,242 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000004_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=312540\n","\t\tFILE: Number of bytes written=921761\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=20\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=95\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=774\n","2024-01-22 22:32:01,242 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000004_0\n","2024-01-22 22:32:01,242 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000005_0\n","2024-01-22 22:32:01,247 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,247 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,247 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,247 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,251 INFO mapred.MapTask: Processing split: file:/root/input/mapred-site.xml:0+758\n","2024-01-22 22:32:01,278 INFO mapreduce.Job: Job job_local2117545184_0001 running in uber mode : false\n","2024-01-22 22:32:01,305 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,305 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,305 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,309 INFO mapreduce.Job:  map 100% reduce 0%\n","2024-01-22 22:32:01,314 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,316 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,327 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,342 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,343 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,349 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000005_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,352 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,352 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000005_0' done.\n","2024-01-22 22:32:01,353 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000005_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=314290\n","\t\tFILE: Number of bytes written=921799\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=21\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=97\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=6\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=758\n","2024-01-22 22:32:01,354 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000005_0\n","2024-01-22 22:32:01,354 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000006_0\n","2024-01-22 22:32:01,355 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,356 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,356 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,356 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,359 INFO mapred.MapTask: Processing split: file:/root/input/yarn-site.xml:0+690\n","2024-01-22 22:32:01,398 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,398 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,398 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,398 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,398 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,399 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,404 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,405 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,412 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000006_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,415 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,415 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000006_0' done.\n","2024-01-22 22:32:01,415 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000006_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=315460\n","\t\tFILE: Number of bytes written=921837\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=19\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=95\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=8\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=690\n","2024-01-22 22:32:01,417 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000006_0\n","2024-01-22 22:32:01,417 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000007_0\n","2024-01-22 22:32:01,427 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,427 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,427 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,428 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,430 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-rbf-site.xml:0+683\n","2024-01-22 22:32:01,461 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,461 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,461 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,461 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,461 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,462 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,467 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,467 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,473 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000007_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,480 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,480 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000007_0' done.\n","2024-01-22 22:32:01,481 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000007_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=316623\n","\t\tFILE: Number of bytes written=921875\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=20\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=99\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=683\n","2024-01-22 22:32:01,483 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000007_0\n","2024-01-22 22:32:01,483 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000008_0\n","2024-01-22 22:32:01,485 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,485 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,485 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,486 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,489 INFO mapred.MapTask: Processing split: file:/root/input/kms-site.xml:0+682\n","2024-01-22 22:32:01,536 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,536 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,536 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,536 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,536 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,537 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,542 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,543 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,548 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000008_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,550 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,564 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000008_0' done.\n","2024-01-22 22:32:01,565 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000008_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=317785\n","\t\tFILE: Number of bytes written=921913\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=20\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=94\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=4\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=682\n","2024-01-22 22:32:01,565 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000008_0\n","2024-01-22 22:32:01,566 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_m_000009_0\n","2024-01-22 22:32:01,576 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,576 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,576 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,577 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,579 INFO mapred.MapTask: Processing split: file:/root/input/httpfs-site.xml:0+620\n","2024-01-22 22:32:01,610 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:01,611 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:01,611 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:01,611 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:01,611 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:01,613 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:01,617 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:01,618 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:01,622 INFO mapred.Task: Task:attempt_local2117545184_0001_m_000009_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,627 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:01,627 INFO mapred.Task: Task 'attempt_local2117545184_0001_m_000009_0' done.\n","2024-01-22 22:32:01,628 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_m_000009_0: Counters: 18\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=318885\n","\t\tFILE: Number of bytes written=921951\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=17\n","\t\tMap output records=0\n","\t\tMap output bytes=0\n","\t\tMap output materialized bytes=6\n","\t\tInput split bytes=97\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tSpilled Records=0\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=620\n","2024-01-22 22:32:01,629 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_m_000009_0\n","2024-01-22 22:32:01,629 INFO mapred.LocalJobRunner: map task executor complete.\n","2024-01-22 22:32:01,635 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n","2024-01-22 22:32:01,635 INFO mapred.LocalJobRunner: Starting task: attempt_local2117545184_0001_r_000000_0\n","2024-01-22 22:32:01,657 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:01,657 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:01,657 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:01,657 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:01,665 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@54bdc41a\n","2024-01-22 22:32:01,669 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-22 22:32:01,704 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2024-01-22 22:32:01,707 INFO reduce.EventFetcher: attempt_local2117545184_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2024-01-22 22:32:01,803 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000003_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,809 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000003_0\n","2024-01-22 22:32:01,818 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2\n","2024-01-22 22:32:01,825 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000000_0 decomp: 21 len: 25 to MEMORY\n","2024-01-22 22:32:01,828 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local2117545184_0001_m_000000_0\n","2024-01-22 22:32:01,829 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21, inMemoryMapOutputs.size() -> 2, commitMemory -> 2, usedMemory ->23\n","2024-01-22 22:32:01,832 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000009_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,840 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000009_0\n","2024-01-22 22:32:01,840 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 23, usedMemory ->25\n","2024-01-22 22:32:01,843 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000006_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,845 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000006_0\n","2024-01-22 22:32:01,845 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 25, usedMemory ->27\n","2024-01-22 22:32:01,848 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000008_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,849 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000008_0\n","2024-01-22 22:32:01,849 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 5, commitMemory -> 27, usedMemory ->29\n","2024-01-22 22:32:01,854 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000005_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,855 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000005_0\n","2024-01-22 22:32:01,855 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 29, usedMemory ->31\n","2024-01-22 22:32:01,858 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000002_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,861 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000002_0\n","2024-01-22 22:32:01,861 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 31, usedMemory ->33\n","2024-01-22 22:32:01,866 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000007_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,868 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000007_0\n","2024-01-22 22:32:01,871 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 33, usedMemory ->35\n","2024-01-22 22:32:01,874 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000004_0 decomp: 2 len: 6 to MEMORY\n","2024-01-22 22:32:01,875 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local2117545184_0001_m_000004_0\n","2024-01-22 22:32:01,875 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 35, usedMemory ->37\n","2024-01-22 22:32:01,877 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local2117545184_0001_m_000001_0 decomp: 20 len: 24 to MEMORY\n","2024-01-22 22:32:01,878 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local2117545184_0001_m_000001_0\n","2024-01-22 22:32:01,879 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 10, commitMemory -> 37, usedMemory ->57\n","2024-01-22 22:32:01,879 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n","2024-01-22 22:32:01,880 INFO mapred.LocalJobRunner: 10 / 10 copied.\n","2024-01-22 22:32:01,881 INFO reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs\n","2024-01-22 22:32:01,890 INFO mapred.Merger: Merging 10 sorted segments\n","2024-01-22 22:32:01,891 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 20 bytes\n","2024-01-22 22:32:01,893 INFO reduce.MergeManagerImpl: Merged 10 segments, 57 bytes to disk to satisfy reduce memory limit\n","2024-01-22 22:32:01,893 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n","2024-01-22 22:32:01,894 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n","2024-01-22 22:32:01,894 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-22 22:32:01,895 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n","2024-01-22 22:32:01,896 INFO mapred.LocalJobRunner: 10 / 10 copied.\n","2024-01-22 22:32:01,933 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n","2024-01-22 22:32:01,935 INFO mapred.Task: Task:attempt_local2117545184_0001_r_000000_0 is done. And is in the process of committing\n","2024-01-22 22:32:01,937 INFO mapred.LocalJobRunner: 10 / 10 copied.\n","2024-01-22 22:32:01,937 INFO mapred.Task: Task attempt_local2117545184_0001_r_000000_0 is allowed to commit now\n","2024-01-22 22:32:01,939 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2117545184_0001_r_000000_0' to file:/content/grep-temp-931962264\n","2024-01-22 22:32:01,940 INFO mapred.LocalJobRunner: reduce > reduce\n","2024-01-22 22:32:01,941 INFO mapred.Task: Task 'attempt_local2117545184_0001_r_000000_0' done.\n","2024-01-22 22:32:01,941 INFO mapred.Task: Final Counters for attempt_local2117545184_0001_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=319345\n","\t\tFILE: Number of bytes written=922141\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=2\n","\t\tReduce shuffle bytes=97\n","\t\tReduce input records=2\n","\t\tReduce output records=2\n","\t\tSpilled Records=2\n","\t\tShuffled Maps =10\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=10\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=147\n","2024-01-22 22:32:01,941 INFO mapred.LocalJobRunner: Finishing task: attempt_local2117545184_0001_r_000000_0\n","2024-01-22 22:32:01,941 INFO mapred.LocalJobRunner: reduce task executor complete.\n","2024-01-22 22:32:02,318 INFO mapreduce.Job:  map 100% reduce 100%\n","2024-01-22 22:32:02,319 INFO mapreduce.Job: Job job_local2117545184_0001 completed successfully\n","2024-01-22 22:32:02,340 INFO mapreduce.Job: Counters: 30\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=3433498\n","\t\tFILE: Number of bytes written=10139923\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=792\n","\t\tMap output records=23\n","\t\tMap output bytes=390\n","\t\tMap output materialized bytes=97\n","\t\tInput split bytes=969\n","\t\tCombine input records=23\n","\t\tCombine output records=2\n","\t\tReduce input groups=2\n","\t\tReduce shuffle bytes=97\n","\t\tReduce input records=2\n","\t\tReduce output records=2\n","\t\tSpilled Records=4\n","\t\tShuffled Maps =10\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=10\n","\t\tGC time elapsed (ms)=67\n","\t\tTotal committed heap usage (bytes)=3952082944\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Input Format Counters \n","\t\tBytes Read=29478\n","\tFile Output Format Counters \n","\t\tBytes Written=147\n","2024-01-22 22:32:02,381 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-22 22:32:02,396 INFO input.FileInputFormat: Total input files to process : 1\n","2024-01-22 22:32:02,400 INFO mapreduce.JobSubmitter: number of splits:1\n","2024-01-22 22:32:02,447 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2055768968_0002\n","2024-01-22 22:32:02,447 INFO mapreduce.JobSubmitter: Executing with tokens: []\n","2024-01-22 22:32:02,615 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n","2024-01-22 22:32:02,616 INFO mapreduce.Job: Running job: job_local2055768968_0002\n","2024-01-22 22:32:02,616 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n","2024-01-22 22:32:02,617 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:02,617 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:02,617 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:02,617 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n","2024-01-22 22:32:02,623 INFO mapred.LocalJobRunner: Waiting for map tasks\n","2024-01-22 22:32:02,623 INFO mapred.LocalJobRunner: Starting task: attempt_local2055768968_0002_m_000000_0\n","2024-01-22 22:32:02,625 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:02,625 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:02,625 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:02,626 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:02,631 INFO mapred.MapTask: Processing split: file:/content/grep-temp-931962264/part-r-00000:0+135\n","2024-01-22 22:32:02,664 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 22:32:02,664 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 22:32:02,664 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 22:32:02,664 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 22:32:02,664 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 22:32:02,666 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 22:32:02,678 INFO mapred.LocalJobRunner: \n","2024-01-22 22:32:02,679 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 22:32:02,679 INFO mapred.MapTask: Spilling map output\n","2024-01-22 22:32:02,679 INFO mapred.MapTask: bufstart = 0; bufend = 33; bufvoid = 104857600\n","2024-01-22 22:32:02,679 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n","2024-01-22 22:32:02,681 INFO mapred.MapTask: Finished spill 0\n","2024-01-22 22:32:02,684 INFO mapred.Task: Task:attempt_local2055768968_0002_m_000000_0 is done. And is in the process of committing\n","2024-01-22 22:32:02,686 INFO mapred.LocalJobRunner: map\n","2024-01-22 22:32:02,686 INFO mapred.Task: Task 'attempt_local2055768968_0002_m_000000_0' done.\n","2024-01-22 22:32:02,687 INFO mapred.Task: Final Counters for attempt_local2055768968_0002_m_000000_0: Counters: 17\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=601006\n","\t\tFILE: Number of bytes written=1841432\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=2\n","\t\tMap output records=2\n","\t\tMap output bytes=33\n","\t\tMap output materialized bytes=43\n","\t\tInput split bytes=111\n","\t\tCombine input records=0\n","\t\tSpilled Records=2\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tFile Input Format Counters \n","\t\tBytes Read=147\n","2024-01-22 22:32:02,687 INFO mapred.LocalJobRunner: Finishing task: attempt_local2055768968_0002_m_000000_0\n","2024-01-22 22:32:02,687 INFO mapred.LocalJobRunner: map task executor complete.\n","2024-01-22 22:32:02,689 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n","2024-01-22 22:32:02,693 INFO mapred.LocalJobRunner: Starting task: attempt_local2055768968_0002_r_000000_0\n","2024-01-22 22:32:02,696 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n","2024-01-22 22:32:02,696 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 22:32:02,697 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 22:32:02,697 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 22:32:02,697 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@338f1d61\n","2024-01-22 22:32:02,700 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-22 22:32:02,702 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2024-01-22 22:32:02,705 INFO reduce.EventFetcher: attempt_local2055768968_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2024-01-22 22:32:02,711 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local2055768968_0002_m_000000_0 decomp: 39 len: 43 to MEMORY\n","2024-01-22 22:32:02,712 INFO reduce.InMemoryMapOutput: Read 39 bytes from map-output for attempt_local2055768968_0002_m_000000_0\n","2024-01-22 22:32:02,712 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->39\n","2024-01-22 22:32:02,713 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n","2024-01-22 22:32:02,714 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-22 22:32:02,714 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2024-01-22 22:32:02,716 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-22 22:32:02,717 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n","2024-01-22 22:32:02,718 INFO reduce.MergeManagerImpl: Merged 1 segments, 39 bytes to disk to satisfy reduce memory limit\n","2024-01-22 22:32:02,719 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n","2024-01-22 22:32:02,719 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n","2024-01-22 22:32:02,719 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-22 22:32:02,719 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n","2024-01-22 22:32:02,720 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-22 22:32:02,724 INFO mapred.Task: Task:attempt_local2055768968_0002_r_000000_0 is done. And is in the process of committing\n","2024-01-22 22:32:02,725 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-22 22:32:02,725 INFO mapred.Task: Task attempt_local2055768968_0002_r_000000_0 is allowed to commit now\n","2024-01-22 22:32:02,727 INFO output.FileOutputCommitter: Saved output of task 'attempt_local2055768968_0002_r_000000_0' to file:/root/grep_example\n","2024-01-22 22:32:02,728 INFO mapred.LocalJobRunner: reduce > reduce\n","2024-01-22 22:32:02,728 INFO mapred.Task: Task 'attempt_local2055768968_0002_r_000000_0' done.\n","2024-01-22 22:32:02,728 INFO mapred.Task: Final Counters for attempt_local2055768968_0002_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=601124\n","\t\tFILE: Number of bytes written=1841509\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=2\n","\t\tReduce shuffle bytes=43\n","\t\tReduce input records=2\n","\t\tReduce output records=2\n","\t\tSpilled Records=2\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=376438784\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=34\n","2024-01-22 22:32:02,728 INFO mapred.LocalJobRunner: Finishing task: attempt_local2055768968_0002_r_000000_0\n","2024-01-22 22:32:02,729 INFO mapred.LocalJobRunner: reduce task executor complete.\n","2024-01-22 22:32:03,616 INFO mapreduce.Job: Job job_local2055768968_0002 running in uber mode : false\n","2024-01-22 22:32:03,617 INFO mapreduce.Job:  map 100% reduce 100%\n","2024-01-22 22:32:03,617 INFO mapreduce.Job: Job job_local2055768968_0002 completed successfully\n","2024-01-22 22:32:03,625 INFO mapreduce.Job: Counters: 30\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=1202130\n","\t\tFILE: Number of bytes written=3682941\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=2\n","\t\tMap output records=2\n","\t\tMap output bytes=33\n","\t\tMap output materialized bytes=43\n","\t\tInput split bytes=111\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=2\n","\t\tReduce shuffle bytes=43\n","\t\tReduce input records=2\n","\t\tReduce output records=2\n","\t\tSpilled Records=4\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=752877568\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Input Format Counters \n","\t\tBytes Read=147\n","\tFile Output Format Counters \n","\t\tBytes Written=34\n"]}]},{"cell_type":"code","metadata":{"id":"mtr0xWbfcA5J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705962724112,"user_tz":-60,"elapsed":6,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"53f16148-173d-4de2-ceec-cc47cdaf4fa6"},"source":["!cat ~/grep_example/*"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["22\tallowed.\n","1\tallowed\n"]}]},{"cell_type":"markdown","metadata":{"id":"AQc3SKkOzNxn"},"source":["**Download 20newsgroups dataset available at** http://qwone.com/~jason/20Newsgroups."]},{"cell_type":"code","metadata":{"id":"vgEGfCcGOswd","executionInfo":{"status":"ok","timestamp":1705962726764,"user_tz":-60,"elapsed":2655,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"cbd5e188-7b5b-44eb-a03f-0cf01a003e10","colab":{"base_uri":"https://localhost:8080/"}},"source":["!wget http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\n","\n","!tar -xzf 20news-18828.tar.gz"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-22 22:32:03--  http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz\n","Resolving qwone.com (qwone.com)... 173.48.205.131\n","Connecting to qwone.com (qwone.com)|173.48.205.131|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14666916 (14M) [application/x-gzip]\n","Saving to: ‘20news-18828.tar.gz’\n","\n","20news-18828.tar.gz 100%[===================>]  13.99M  14.6MB/s    in 1.0s    \n","\n","2024-01-22 22:32:05 (14.6 MB/s) - ‘20news-18828.tar.gz’ saved [14666916/14666916]\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"oxCFNl3SQHDl"},"source":["#Hadoop Streaming"]},{"cell_type":"markdown","metadata":{"id":"joVB86muCJy2"},"source":["Hadoop streaming permite crear y ejecutar trabajos Map/Reduce con cualquier ejecutable o script como mapeador y/o reductor.\n","\n","Mas información sobre Map/Reduce en el siguiente [enlace](https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)"]},{"cell_type":"code","metadata":{"id":"bLRsjubgOs2p","colab":{"base_uri":"https://localhost:8080/"},"outputId":"86009017-52d9-4310-a744-87a90bcc9f5b","executionInfo":{"status":"ok","timestamp":1705962733294,"user_tz":-60,"elapsed":1413,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}}},"source":["!find / -name 'hadoop-streaming*.jar'"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["find: ‘/proc/62/task/62/net’: Invalid argument\n","find: ‘/proc/62/net’: Invalid argument\n","/usr/local/hadoop-3.3.6/share/hadoop/tools/sources/hadoop-streaming-3.3.6-test-sources.jar\n","/usr/local/hadoop-3.3.6/share/hadoop/tools/sources/hadoop-streaming-3.3.6-sources.jar\n","/usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n","/content/hadoop-3.3.6/share/hadoop/tools/sources/hadoop-streaming-3.3.6-test-sources.jar\n","/content/hadoop-3.3.6/share/hadoop/tools/sources/hadoop-streaming-3.3.6-sources.jar\n","/content/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar\n"]}]},{"cell_type":"markdown","metadata":{"id":"J368kEgWFpNh"},"source":["**mapper.py**\n","\n","Leerá los datos de *STDIN*, los dividirá en palabras y enviará a *STDOUT* una lista de líneas que asignan las palabras a sus recuentos.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W7ZO_qx9CMN2","executionInfo":{"status":"ok","timestamp":1705964555467,"user_tz":-60,"elapsed":7,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"b4d58b29-a9ff-4fcb-933a-671b6efc1cea"},"source":["!cat /content/mapper.py"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["# -*- coding: utf-8 -*-\n","\"\"\"mapper.ipynb\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1yCwGyMXJT2qt3_58aLOOiJXO0GIaPcJd\n","\"\"\"\n","\n","\n","\n","import sys\n","import io\n","import re\n","import nltk\n","nltk.download('stopwords',quiet=True)\n","from nltk.corpus import stopwords\n","punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n","\n","stop_words = set(stopwords.words('english'))\n","input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='latin1')\n","for line in input_stream:\n","  line = line.strip()\n","  line = re.sub(r'[^\\w\\s]', '',line)\n","  line = line.lower()\n","  for x in line:\n","    if x in punctuations:\n","      line=line.replace(x, \" \") \n","\n","  words=line.split()\n","  for word in words: \n","    if word not in stop_words:\n","      print('%s\\t%s' % (word, 1))"]}]},{"cell_type":"markdown","metadata":{"id":"xMNDwMH3FvZp"},"source":["**reducer.py**\n","\n","Leerá los resultados de mapper.py desde STDIN y sumará las ocurrencias de cada palabra hasta llegar a un recuento final, y luego enviará sus resultados a STDOUT."]},{"cell_type":"code","metadata":{"id":"RaAGwdm1F0bg","executionInfo":{"status":"ok","timestamp":1705964575547,"user_tz":-60,"elapsed":259,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"e94561b2-118f-4386-82e0-62e464d28a48","colab":{"base_uri":"https://localhost:8080/"}},"source":["!cat /content/reducer.py"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["# -*- coding: utf-8 -*-\n","\"\"\"reducer.ipynb\n","\n","Automatically generated by Colaboratory.\n","\n","Original file is located at\n","    https://colab.research.google.com/drive/1YzJ-vUsO5VYCyMrfPMow3s2IdxXkyQ0i\n","\"\"\"\n","\n","from operator import itemgetter\n","import sys\n","\n","current_word = None\n","current_count = 0\n","word = None\n","\n","# input comes from STDIN\n","for line in sys.stdin:\n","    # remove leading and trailing whitespace\n","    line = line.strip()\n","    line=line.lower()\n","\n","    # parse the input we got from mapper.py\n","    word, count = line.split('\\t', 1)\n","    try:\n","      count = int(count)\n","    except ValueError:\n","      #count was not a number, so silently\n","      #ignore/discard this line\n","      continue\n","\n","    # this IF-switch only works because Hadoop sorts map output\n","    # by key (here: word) before it is passed to the reducer\n","    if current_word == word:\n","        current_count += count\n","    else:\n","        if current_word:\n","            # write result to STDOUT\n","            print ('%s\\t%s' % (current_word, current_count))\n","        current_count = count\n","        current_word = word\n","\n","# do not forget to output the last word if needed!\n","if current_word == word:\n","    print( '%s\\t%s' % (current_word, current_count))\n","\n","\n","\n"]}]},{"cell_type":"code","metadata":{"id":"eu5IAGT2Os6D","executionInfo":{"status":"ok","timestamp":1705964757207,"user_tz":-60,"elapsed":278,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}}},"source":["!chmod u+rwx /content/mapper.py\n","!chmod u+rwx /content/reducer.py"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"ru1lPx9yOsvO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705964770674,"user_tz":-60,"elapsed":10027,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"ae6ceb26-663a-4c52-cd7d-01e060a07888"},"source":["!/usr/local/hadoop-3.3.6/bin/hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar -input /content/20news-18828/alt.atheism/49960 -output /content/output -file /content/mapper.py  -file /content/reducer.py  -mapper 'python mapper.py'  -reducer 'python reducer.py'"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-22 23:06:02,122 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n","packageJobJar: [/content/mapper.py, /content/reducer.py] [] /tmp/streamjob4108329902331990602.jar tmpDir=null\n","2024-01-22 23:06:03,147 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n","2024-01-22 23:06:03,365 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n","2024-01-22 23:06:03,365 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n","2024-01-22 23:06:03,416 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-22 23:06:03,754 INFO mapred.FileInputFormat: Total input files to process : 1\n","2024-01-22 23:06:03,803 INFO mapreduce.JobSubmitter: number of splits:1\n","2024-01-22 23:06:04,220 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local916389681_0001\n","2024-01-22 23:06:04,220 INFO mapreduce.JobSubmitter: Executing with tokens: []\n","2024-01-22 23:06:04,855 INFO mapred.LocalDistributedCacheManager: Localized file:/content/mapper.py as file:/tmp/hadoop-root/mapred/local/job_local916389681_0001_9519fe46-62c3-43e9-bb9c-fb48edc841e5/mapper.py\n","2024-01-22 23:06:04,929 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer.py as file:/tmp/hadoop-root/mapred/local/job_local916389681_0001_1b63ca26-2ada-46c9-ba27-69ffe48764b0/reducer.py\n","2024-01-22 23:06:05,137 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n","2024-01-22 23:06:05,140 INFO mapreduce.Job: Running job: job_local916389681_0001\n","2024-01-22 23:06:05,150 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n","2024-01-22 23:06:05,153 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n","2024-01-22 23:06:05,168 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 23:06:05,168 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 23:06:05,303 INFO mapred.LocalJobRunner: Waiting for map tasks\n","2024-01-22 23:06:05,315 INFO mapred.LocalJobRunner: Starting task: attempt_local916389681_0001_m_000000_0\n","2024-01-22 23:06:05,394 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 23:06:05,397 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 23:06:05,497 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 23:06:05,534 INFO mapred.MapTask: Processing split: file:/content/20news-18828/alt.atheism/49960:0+11599\n","2024-01-22 23:06:05,579 INFO mapred.MapTask: numReduceTasks: 1\n","2024-01-22 23:06:05,858 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n","2024-01-22 23:06:05,858 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n","2024-01-22 23:06:05,858 INFO mapred.MapTask: soft limit at 83886080\n","2024-01-22 23:06:05,859 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n","2024-01-22 23:06:05,859 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n","2024-01-22 23:06:05,867 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n","2024-01-22 23:06:05,883 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, mapper.py]\n","2024-01-22 23:06:05,905 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n","2024-01-22 23:06:05,906 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n","2024-01-22 23:06:05,907 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n","2024-01-22 23:06:05,916 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n","2024-01-22 23:06:05,917 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n","2024-01-22 23:06:05,917 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n","2024-01-22 23:06:05,919 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n","2024-01-22 23:06:05,920 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n","2024-01-22 23:06:05,920 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n","2024-01-22 23:06:05,920 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n","2024-01-22 23:06:05,921 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n","2024-01-22 23:06:05,922 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n","2024-01-22 23:06:05,974 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:05,974 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:05,977 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:06,153 INFO mapreduce.Job: Job job_local916389681_0001 running in uber mode : false\n","2024-01-22 23:06:06,154 INFO mapreduce.Job:  map 0% reduce 0%\n","2024-01-22 23:06:08,998 INFO streaming.PipeMapRed: Records R/W=293/1\n","2024-01-22 23:06:09,219 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-22 23:06:09,220 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-22 23:06:09,223 INFO mapred.LocalJobRunner: \n","2024-01-22 23:06:09,224 INFO mapred.MapTask: Starting flush of map output\n","2024-01-22 23:06:09,224 INFO mapred.MapTask: Spilling map output\n","2024-01-22 23:06:09,224 INFO mapred.MapTask: bufstart = 0; bufend = 10685; bufvoid = 104857600\n","2024-01-22 23:06:09,224 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209920(104839680); length = 4477/6553600\n","2024-01-22 23:06:09,251 INFO mapred.MapTask: Finished spill 0\n","2024-01-22 23:06:09,275 INFO mapred.Task: Task:attempt_local916389681_0001_m_000000_0 is done. And is in the process of committing\n","2024-01-22 23:06:09,281 INFO mapred.LocalJobRunner: Records R/W=293/1\n","2024-01-22 23:06:09,281 INFO mapred.Task: Task 'attempt_local916389681_0001_m_000000_0' done.\n","2024-01-22 23:06:09,292 INFO mapred.Task: Final Counters for attempt_local916389681_0001_m_000000_0: Counters: 17\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=15021\n","\t\tFILE: Number of bytes written=656510\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=293\n","\t\tMap output records=1120\n","\t\tMap output bytes=10685\n","\t\tMap output materialized bytes=12931\n","\t\tInput split bytes=96\n","\t\tCombine input records=0\n","\t\tSpilled Records=1120\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=0\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=404750336\n","\tFile Input Format Counters \n","\t\tBytes Read=11599\n","2024-01-22 23:06:09,293 INFO mapred.LocalJobRunner: Finishing task: attempt_local916389681_0001_m_000000_0\n","2024-01-22 23:06:09,293 INFO mapred.LocalJobRunner: map task executor complete.\n","2024-01-22 23:06:09,297 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n","2024-01-22 23:06:09,297 INFO mapred.LocalJobRunner: Starting task: attempt_local916389681_0001_r_000000_0\n","2024-01-22 23:06:09,310 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n","2024-01-22 23:06:09,310 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n","2024-01-22 23:06:09,310 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n","2024-01-22 23:06:09,318 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@46373b75\n","2024-01-22 23:06:09,320 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n","2024-01-22 23:06:09,352 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n","2024-01-22 23:06:09,358 INFO reduce.EventFetcher: attempt_local916389681_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n","2024-01-22 23:06:09,404 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local916389681_0001_m_000000_0 decomp: 12927 len: 12931 to MEMORY\n","2024-01-22 23:06:09,410 INFO reduce.InMemoryMapOutput: Read 12927 bytes from map-output for attempt_local916389681_0001_m_000000_0\n","2024-01-22 23:06:09,413 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 12927, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12927\n","2024-01-22 23:06:09,417 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n","2024-01-22 23:06:09,418 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-22 23:06:09,418 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n","2024-01-22 23:06:09,428 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-22 23:06:09,428 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12914 bytes\n","2024-01-22 23:06:09,440 INFO reduce.MergeManagerImpl: Merged 1 segments, 12927 bytes to disk to satisfy reduce memory limit\n","2024-01-22 23:06:09,441 INFO reduce.MergeManagerImpl: Merging 1 files, 12931 bytes from disk\n","2024-01-22 23:06:09,442 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n","2024-01-22 23:06:09,442 INFO mapred.Merger: Merging 1 sorted segments\n","2024-01-22 23:06:09,448 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 12914 bytes\n","2024-01-22 23:06:09,449 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-22 23:06:09,463 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer.py]\n","2024-01-22 23:06:09,468 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n","2024-01-22 23:06:09,472 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n","2024-01-22 23:06:09,490 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:09,490 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:09,492 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:09,511 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n","2024-01-22 23:06:09,594 INFO streaming.PipeMapRed: Records R/W=1120/1\n","2024-01-22 23:06:09,609 INFO streaming.PipeMapRed: MRErrorThread done\n","2024-01-22 23:06:09,612 INFO streaming.PipeMapRed: mapRedFinished\n","2024-01-22 23:06:09,615 INFO mapred.Task: Task:attempt_local916389681_0001_r_000000_0 is done. And is in the process of committing\n","2024-01-22 23:06:09,616 INFO mapred.LocalJobRunner: 1 / 1 copied.\n","2024-01-22 23:06:09,617 INFO mapred.Task: Task attempt_local916389681_0001_r_000000_0 is allowed to commit now\n","2024-01-22 23:06:09,619 INFO output.FileOutputCommitter: Saved output of task 'attempt_local916389681_0001_r_000000_0' to file:/content/output\n","2024-01-22 23:06:09,620 INFO mapred.LocalJobRunner: Records R/W=1120/1 > reduce\n","2024-01-22 23:06:09,620 INFO mapred.Task: Task 'attempt_local916389681_0001_r_000000_0' done.\n","2024-01-22 23:06:09,621 INFO mapred.Task: Final Counters for attempt_local916389681_0001_r_000000_0: Counters: 24\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=40915\n","\t\tFILE: Number of bytes written=677139\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=787\n","\t\tReduce shuffle bytes=12931\n","\t\tReduce input records=1120\n","\t\tReduce output records=787\n","\t\tSpilled Records=1120\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=404750336\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Output Format Counters \n","\t\tBytes Written=7698\n","2024-01-22 23:06:09,621 INFO mapred.LocalJobRunner: Finishing task: attempt_local916389681_0001_r_000000_0\n","2024-01-22 23:06:09,621 INFO mapred.LocalJobRunner: reduce task executor complete.\n","2024-01-22 23:06:10,160 INFO mapreduce.Job:  map 100% reduce 100%\n","2024-01-22 23:06:10,161 INFO mapreduce.Job: Job job_local916389681_0001 completed successfully\n","2024-01-22 23:06:10,192 INFO mapreduce.Job: Counters: 30\n","\tFile System Counters\n","\t\tFILE: Number of bytes read=55936\n","\t\tFILE: Number of bytes written=1333649\n","\t\tFILE: Number of read operations=0\n","\t\tFILE: Number of large read operations=0\n","\t\tFILE: Number of write operations=0\n","\tMap-Reduce Framework\n","\t\tMap input records=293\n","\t\tMap output records=1120\n","\t\tMap output bytes=10685\n","\t\tMap output materialized bytes=12931\n","\t\tInput split bytes=96\n","\t\tCombine input records=0\n","\t\tCombine output records=0\n","\t\tReduce input groups=787\n","\t\tReduce shuffle bytes=12931\n","\t\tReduce input records=1120\n","\t\tReduce output records=787\n","\t\tSpilled Records=2240\n","\t\tShuffled Maps =1\n","\t\tFailed Shuffles=0\n","\t\tMerged Map outputs=1\n","\t\tGC time elapsed (ms)=0\n","\t\tTotal committed heap usage (bytes)=809500672\n","\tShuffle Errors\n","\t\tBAD_ID=0\n","\t\tCONNECTION=0\n","\t\tIO_ERROR=0\n","\t\tWRONG_LENGTH=0\n","\t\tWRONG_MAP=0\n","\t\tWRONG_REDUCE=0\n","\tFile Input Format Counters \n","\t\tBytes Read=11599\n","\tFile Output Format Counters \n","\t\tBytes Written=7698\n","2024-01-22 23:06:10,192 INFO streaming.StreamJob: Output directory: /content/output\n"]}]},{"cell_type":"code","metadata":{"id":"jiW5mPIcy_Jp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705964835691,"user_tz":-60,"elapsed":274,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"fcdc5590-f24a-4d06-ca5c-caffa1653e64"},"source":["!ls /content/output"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["part-00000  _SUCCESS\n"]}]},{"cell_type":"code","metadata":{"id":"CTFjOm59kc04","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705964843036,"user_tz":-60,"elapsed":262,"user":{"displayName":"Miguel Ronda","userId":"13437494457168354933"}},"outputId":"9c0c1f52-03cd-4c87-a3e0-0383bfbcc205"},"source":["!cat /content/output/part-00000"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["034529887x\t1\n","0511211216\t1\n","071\t5\n","080182494x\t1\n","0801834074\t1\n","0877226423\t1\n","0877227675\t1\n","0908\t1\n","0910309264\t1\n","1\t1\n","10\t1\n","11\t1\n","1266\t1\n","1271\t1\n","14\t1\n","140195\t1\n","14215\t1\n","14226\t1\n","142282197\t1\n","17701900\t1\n","1881\t1\n","1977\t1\n","1981\t1\n","1986\t1\n","1988\t1\n","1989\t1\n","1990\t1\n","1992\t1\n","20th\t1\n","226\t1\n","24hour\t1\n","2568900\t1\n","272\t1\n","273\t1\n","2nd\t1\n","3005\t1\n","316\t1\n","372\t1\n","3d\t1\n","3nl\t1\n","4\t1\n","41\t2\n","430\t2\n","4581244\t1\n","4679525\t1\n","490\t1\n","495\t2\n","4rh\t1\n","4rl\t1\n","512\t2\n","53701\t1\n","541\t1\n","59\t1\n","608\t1\n","664\t1\n","700\t1\n","702\t1\n","7119\t1\n","716\t1\n","7215\t1\n","7251\t1\n","750\t1\n","7723\t1\n","787140195\t1\n","787522973\t1\n","831\t1\n","8372475\t1\n","88\t1\n","880\t2\n","8964079\t1\n","8ew\t1\n","91605\t1\n","aah\t1\n","aap\t2\n","abortions\t1\n","absurdities\t1\n","accompanied\t1\n","accounts\t1\n","address\t1\n","addresses\t2\n","adulteries\t1\n","aesthetics\t1\n","african\t3\n","africanamericans\t1\n","agnostic\t1\n","al\t1\n","alien\t1\n","allen\t2\n","also\t3\n","altatheism\t1\n","altatheismarchivename\t1\n","altatheismmoderated\t1\n","alternate\t1\n","alternative\t1\n","although\t2\n","america\t1\n","american\t5\n","americans\t2\n","amherst\t1\n","amongst\t1\n","amusing\t1\n","ancient\t1\n","andor\t1\n","another\t1\n","anselm\t1\n","anthology\t3\n","anyone\t1\n","appendix\t2\n","approachable\t1\n","archive\t1\n","archivename\t1\n","archives\t1\n","archiveservermantiscouk\t1\n","area\t2\n","argues\t1\n","arguments\t5\n","articles\t1\n","assassinated\t1\n","assisted\t1\n","association\t2\n","assorted\t3\n","atheism\t6\n","atheismindex\t1\n","atheismresources\t1\n","atheist\t10\n","atheisten\t2\n","atheistic\t1\n","atomic\t2\n","atoms\t1\n","atrocities\t1\n","attempt\t1\n","attempts\t1\n","attention\t1\n","atwood\t1\n","atwoods\t1\n","austin\t2\n","authors\t1\n","available\t2\n","axiarchism\t1\n","back\t1\n","ball\t2\n","ballantine\t1\n","baltimore\t1\n","bank\t1\n","bantam\t1\n","based\t2\n","bay\t1\n","beam\t1\n","became\t1\n","become\t1\n","began\t1\n","begins\t1\n","belief\t2\n","believed\t1\n","beneath\t1\n","berkeley\t1\n","berlin\t2\n","best\t1\n","better\t1\n","beyond\t1\n","bible\t7\n","biblebeliever\t1\n","biblical\t1\n","bibliography\t1\n","bizarre\t1\n","black\t2\n","blueprints\t1\n","book\t4\n","books\t11\n","box\t3\n","brain\t2\n","britain\t1\n","british\t1\n","bucherdienst\t1\n","buffalo\t3\n","bumper\t1\n","bund\t1\n","ca\t1\n","cameron\t1\n","canticle\t1\n","canyon\t1\n","card\t1\n","cardiffs\t1\n","carries\t1\n","cars\t1\n","case\t1\n","catalog\t1\n","cathedral\t1\n","catholic\t1\n","centuries\t1\n","century\t1\n","challenging\t1\n","characters\t2\n","charge\t1\n","chilling\t1\n","christ\t1\n","christian\t4\n","christianity\t4\n","christians\t2\n","church\t1\n","clarendon\t1\n","classical\t2\n","claus\t1\n","clerical\t1\n","closed\t1\n","cohen\t1\n","coherence\t1\n","compared\t1\n","comply\t1\n","comprehensive\t3\n","compromise\t1\n","conceived\t1\n","concentrating\t1\n","concept\t1\n","concluded\t1\n","conduit\t1\n","congress\t2\n","considering\t1\n","considers\t1\n","construct\t1\n","containing\t1\n","contains\t3\n","contemporary\t1\n","contempory\t1\n","contradictions\t2\n","contradicts\t1\n","conway\t1\n","copying\t1\n","covering\t1\n","craftsmen\t1\n","creed\t2\n","crimes\t1\n","criticized\t1\n","critique\t1\n","critiques\t1\n","d1000\t2\n","d3000\t1\n","darwin\t4\n","davy\t1\n","day\t1\n","de\t2\n","dead\t2\n","death\t1\n","december\t1\n","decisively\t1\n","defences\t1\n","defining\t1\n","deity\t2\n","delight\t1\n","deluxe\t1\n","demand\t1\n","demonstrates\t1\n","der\t3\n","derived\t1\n","des\t1\n","descartes\t1\n","describe\t1\n","description\t1\n","designs\t3\n","detailed\t1\n","developments\t1\n","devil\t1\n","diary\t1\n","dick\t3\n","dictionary\t1\n","die\t1\n","diener\t1\n","different\t2\n","difficult\t1\n","direct\t1\n","directly\t1\n","disch\t1\n","dismissively\t1\n","divine\t2\n","doctors\t1\n","dogmatic\t1\n","doomsday\t2\n","drive\t1\n","droemerknaur\t1\n","dull\t1\n","dunkle\t1\n","earth\t2\n","earthers\t1\n","east\t1\n","easy\t1\n","edgar\t1\n","edition\t3\n","editor\t1\n","edmund\t1\n","effect\t1\n","emphasis\t1\n","england\t1\n","enlighting\t1\n","erste\t1\n","et\t1\n","etc\t1\n","ethical\t1\n","ev\t2\n","even\t1\n","events\t1\n","evil\t1\n","evolution\t3\n","examiner\t1\n","examines\t1\n","example\t1\n","existence\t5\n","exists\t3\n","explicitly\t1\n","expressed\t1\n","faith\t2\n","fallacies\t1\n","fallible\t1\n","faq\t1\n","fate\t1\n","fax\t2\n","feet\t1\n","fernwright\t1\n","ffrf\t1\n","fiction\t1\n","fictitious\t1\n","figmonetcomcom\t1\n","files\t1\n","filling\t1\n","fired\t1\n","first\t1\n","fish\t6\n","focusses\t1\n","following\t1\n","foote\t2\n","forbids\t1\n","formalistic\t1\n","foundation\t2\n","founded\t1\n","france\t1\n","francisco\t1\n","freedom\t2\n","freethinker\t1\n","freethought\t2\n","friend\t1\n","fundamentalists\t2\n","fuss\t1\n","galactic\t1\n","gem\t1\n","george\t1\n","german\t1\n","germany\t4\n","get\t3\n","giant\t1\n","glenn\t1\n","gnostic\t1\n","go\t1\n","god\t13\n","gods\t3\n","goes\t1\n","gold\t1\n","gordon\t1\n","gottes\t1\n","great\t3\n","group\t1\n","grows\t1\n","gw\t1\n","hall\t1\n","handbook\t1\n","handmaids\t1\n","handwaving\t1\n","hanged\t1\n","hannover\t1\n","hardcover\t2\n","haught\t1\n","haughts\t1\n","help\t1\n","hero\t1\n","hidden\t1\n","high\t1\n","history\t6\n","holloway\t1\n","hollywood\t1\n","holy\t2\n","hopkins\t1\n","horrors\t2\n","however\t1\n","hrsg\t1\n","humanism\t5\n","humanist\t1\n","hume\t1\n","hunted\t1\n","ibdk\t1\n","ibka\t3\n","idea\t2\n","ie\t1\n","ill\t1\n","illustrated\t1\n","immoralities\t2\n","implicitly\t1\n","imputation\t1\n","includes\t3\n","including\t2\n","incoherent\t2\n","inductive\t1\n","information\t1\n","informationen\t1\n","ink\t1\n","inside\t1\n","intellectual\t1\n","internationaler\t2\n","invades\t1\n","invasion\t1\n","ironic\t1\n","isbn\t5\n","islington\t1\n","j\t1\n","james\t3\n","joe\t1\n","johns\t1\n","journal\t2\n","jr\t3\n","justification\t2\n","k\t2\n","kant\t1\n","kierkegaard\t1\n","kind\t1\n","king\t1\n","kingdom\t1\n","know\t1\n","konfessionslosen\t2\n","konfessionslosesn\t1\n","kung\t1\n","l\t1\n","lambs\t1\n","laser\t1\n","lastmodified\t1\n","late\t1\n","laurel\t1\n","leaving\t1\n","legal\t1\n","leibowitz\t2\n","lelies\t1\n","less\t1\n","letters\t1\n","library\t1\n","life\t1\n","like\t1\n","lines\t1\n","lion\t1\n","listening\t1\n","listing\t1\n","lists\t1\n","live\t1\n","lives\t1\n","living\t1\n","london\t4\n","looks\t1\n","luxuries\t1\n","lynn\t2\n","mackie\t2\n","mackies\t1\n","madison\t1\n","madness\t1\n","magazine\t1\n","mail\t2\n","mailbased\t1\n","mailing\t1\n","mainly\t1\n","mainstream\t1\n","make\t1\n","makes\t1\n","making\t1\n","man\t1\n","mantiscouk\t1\n","many\t3\n","margaret\t1\n","martin\t1\n","martins\t1\n","materialien\t1\n","mathew\t2\n","mathewmantiscouk\t1\n","may\t1\n","maze\t1\n","md\t1\n","men\t1\n","met\t1\n","michael\t1\n","miller\t1\n","mind\t1\n","miracle\t2\n","miz\t1\n","mizvertrieb\t1\n","monks\t1\n","monthly\t1\n","moral\t1\n","morality\t1\n","moulded\t1\n","murder\t1\n","music\t1\n","must\t1\n","mysteries\t1\n","mysteriously\t1\n","n1\t1\n","n19\t1\n","nation\t1\n","national\t2\n","necessarily\t1\n","negative\t1\n","neither\t1\n","net\t2\n","new\t4\n","newer\t1\n","newman\t1\n","newsletter\t1\n","nonbelief\t1\n","nonexistence\t1\n","nonfiction\t1\n","norm\t2\n","north\t1\n","noteworthy\t1\n","novel\t3\n","novels\t2\n","noyes\t1\n","number\t2\n","ny\t2\n","obscure\t1\n","observations\t1\n","oceans\t1\n","odd\t1\n","often\t3\n","old\t2\n","older\t1\n","one\t3\n","ones\t1\n","opinions\t1\n","organization\t1\n","organizations\t1\n","origin\t1\n","origins\t1\n","outlawed\t1\n","outstanding\t1\n","oxford\t2\n","pages\t4\n","paid\t1\n","pangborn\t1\n","papal\t1\n","paper\t3\n","paperback\t1\n","paperbacks\t1\n","papsttums\t1\n","paraphernalia\t1\n","particular\t1\n","particularly\t1\n","passage\t1\n","people\t6\n","per\t1\n","performed\t1\n","period\t1\n","persecution\t1\n","persons\t1\n","peter\t1\n","philadelphia\t1\n","philip\t2\n","philips\t1\n","philosophical\t3\n","philosophy\t1\n","pink\t1\n","place\t1\n","planet\t1\n","plantinga\t1\n","plastic\t1\n","platinga\t1\n","po\t3\n","polished\t1\n","politisches\t1\n","popular\t1\n","positions\t2\n","positive\t1\n","possibly\t1\n","post\t2\n","postfach\t3\n","posthumous\t1\n","postpaid\t1\n","pothealer\t2\n","pp\t1\n","pregnant\t1\n","premise\t1\n","present\t2\n","press\t8\n","price\t1\n","principal\t1\n","probably\t1\n","produce\t1\n","prometheus\t5\n","promoting\t1\n","proof\t1\n","property\t1\n","publish\t4\n","punished\t1\n","push\t1\n","quarterly\t1\n","quickly\t1\n","quite\t1\n","quotations\t2\n","r\t2\n","radio\t1\n","raise\t1\n","rambling\t1\n","range\t1\n","ranges\t1\n","rather\t2\n","rational\t1\n","rationalism\t1\n","rationalist\t1\n","read\t1\n","reading\t1\n","readings\t1\n","reality\t1\n","realm\t1\n","reason\t1\n","rebut\t1\n","recent\t1\n","red\t1\n","refreshingly\t1\n","refutations\t1\n","refuting\t1\n","rejected\t1\n","relevance\t1\n","religion\t6\n","religious\t3\n","rely\t1\n","remained\t1\n","remote\t1\n","replacements\t1\n","reply\t1\n","resources\t4\n","restatements\t1\n","retroactively\t1\n","returns\t1\n","review\t1\n","revised\t2\n","revoked\t1\n","richard\t1\n","right\t2\n","road\t2\n","rosa\t2\n","saint\t1\n","san\t1\n","santa\t2\n","saying\t1\n","sceptical\t1\n","schizophrenic\t1\n","scholarly\t1\n","searches\t1\n","second\t1\n","secular\t3\n","secularization\t1\n","see\t2\n","seems\t1\n","seite\t1\n","seldes\t1\n","sell\t2\n","send\t2\n","series\t1\n","server\t1\n","set\t2\n","sf\t1\n","sheets\t1\n","short\t2\n","sidgwick\t1\n","similarity\t1\n","simple\t1\n","sinful\t1\n","single\t1\n","small\t1\n","society\t3\n","somewhat\t3\n","sort\t1\n","south\t1\n","spent\t1\n","square\t1\n","star\t1\n","statements\t1\n","states\t1\n","stein\t1\n","stick\t1\n","stickers\t1\n","stories\t2\n","story\t2\n","street\t2\n","study\t1\n","style\t1\n","subject\t1\n","subjects\t1\n","substance\t1\n","subtitled\t1\n","summons\t1\n","supposedly\t1\n","suppressed\t1\n","sure\t1\n","swinburne\t6\n","symbol\t1\n","system\t1\n","take\t1\n","tale\t2\n","technology\t1\n","technologybased\t1\n","telephone\t4\n","temple\t2\n","tendentious\t2\n","terminally\t1\n","terminology\t1\n","theism\t3\n","theists\t1\n","theocracy\t1\n","theres\t1\n","theses\t1\n","think\t1\n","thomas\t1\n","thoughtprovoking\t1\n","thoughts\t1\n","times\t2\n","traces\t1\n","translation\t1\n","tries\t1\n","trilogy\t1\n","true\t1\n","truth\t1\n","try\t1\n","turner\t1\n","twisted\t1\n","tx\t2\n","uh\t1\n","ultimate\t1\n","ultimately\t1\n","unable\t1\n","unbelief\t2\n","uncovering\t1\n","und\t3\n","unfortunately\t1\n","united\t1\n","university\t3\n","unknown\t1\n","unsupportable\t1\n","upon\t1\n","us\t3\n","usa\t4\n","usage\t1\n","use\t1\n","used\t2\n","valis\t1\n","values\t1\n","various\t3\n","version\t3\n","versions\t1\n","vicars\t1\n","views\t1\n","volume\t2\n","walter\t1\n","way\t2\n","wc1r\t2\n","well\t2\n","western\t1\n","whether\t1\n","white\t1\n","whose\t1\n","wi\t1\n","wide\t1\n","wired\t1\n","without\t4\n","woman\t1\n","womans\t1\n","women\t1\n","womens\t1\n","word\t1\n","work\t2\n","works\t1\n","world\t1\n","worldview\t2\n","worth\t1\n","wp\t1\n","write\t6\n","writing\t1\n","writings\t1\n","written\t2\n","wrote\t3\n","york\t2\n","youll\t1\n","young\t1\n","zeit\t1\n","zur\t1\n","ÿ\t1\n"]}]}]}