{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myPIGP-mwKBD"
   },
   "source": [
    "# Instalación de Hadoop\n",
    "\n",
    "Hadoop es un marco de programación basado en Java que permite procesar y almacenar conjuntos de datos extremadamente grandes en un clúster de máquinas de bajo coste. Fue el primer gran proyecto de código abierto en el ámbito del Big Data y está patrocinado por la Apache Software Foundation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9bT9M1yvyXG"
   },
   "source": [
    "## Paso 1: Instalación de Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36406,
     "status": "ok",
     "timestamp": 1705940008177,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "bijZAdD_cBMK",
    "outputId": "f5873048-eee4-454b-8466-37ef52dd3003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-22 16:12:51--  https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n",
      "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.95.219, 2a01:4f8:10a:201a::2, ...\n",
      "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 730107476 (696M) [application/x-gzip]\n",
      "Saving to: ‘hadoop-3.3.6.tar.gz’\n",
      "\n",
      "hadoop-3.3.6.tar.gz 100%[===================>] 696.28M  20.3MB/s    in 36s     \n",
      "\n",
      "2024-01-22 16:13:27 (19.6 MB/s) - ‘hadoop-3.3.6.tar.gz’ saved [730107476/730107476]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mj40txsTw6DZ"
   },
   "source": [
    "utilizaremos el comando tar con los parámetros:\n",
    "- -x para extraer,\n",
    "- -z para descomprimir,\n",
    "- -f para especificar que estamos extrayendo de un archivo\n",
    "\n",
    "podremos añadir -v para la salida en detalle,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVce513-cBHm"
   },
   "outputs": [],
   "source": [
    "!tar -xzf hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMhnqrDxxYsx"
   },
   "source": [
    "Copiamos el directorio de hadoop en */usr/local*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JF-ze-YOdync"
   },
   "outputs": [],
   "source": [
    "!cp -r hadoop-3.3.6/ /usr/local/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vh6Dqbbrwqpe"
   },
   "source": [
    "## Step 2: Configurar el Hadoop JAVA HOME\n",
    "\n",
    "Hadoop requiere que se establezca la ruta de acceso a Java, ya sea como una variable de entorno o en el archivo de configuración de Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GowOFc6zxqbC"
   },
   "source": [
    "1. Buscamos cual es la dirección de Java en la máquina Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1705940030692,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "_OUc19ZtcBG5",
    "outputId": "7c9bc594-11f0-48ff-c4a0-91bcad8f02bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/jvm/java-11-openjdk-amd64/\n"
     ]
    }
   ],
   "source": [
    "!readlink -f /usr/bin/java | sed \"s:bin/java::\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxaPBWRKxXta"
   },
   "source": [
    "2. Establecemos mediante código Python el valor de esta variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsWEEcqfpQWY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj00rPPZyEWZ"
   },
   "source": [
    "# Step 3: Ejecutando Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWC8Ab-IyI8w"
   },
   "source": [
    "- Comprobamos la versión de Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 884,
     "status": "ok",
     "timestamp": 1705940201601,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "MumBMiYjp35-",
    "outputId": "a651023b-25cc-4220-8e4c-ba320020e7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop 3.3.6\n",
      "Source code repository https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c\n",
      "Compiled by ubuntu on 2023-06-18T08:22Z\n",
      "Compiled on platform linux-x86_64\n",
      "Compiled with protoc 3.7.1\n",
      "From source with checksum 5652179ad55f76cb287d9c633bb53bbd\n",
      "This command was run using /usr/local/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6.jar\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/hadoop-3.3.6/bin/hadoop version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZSUvOFKyMSY"
   },
   "source": [
    "- Ejecutamos el comando sin parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1705940032652,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "Zhf-zK7NcBDF",
    "outputId": "6075716c-6da3-4509-d21f-e63dd570cc2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: hadoop [OPTIONS] SUBCOMMAND [SUBCOMMAND OPTIONS]\n",
      " or    hadoop [OPTIONS] CLASSNAME [CLASSNAME OPTIONS]\n",
      "  where CLASSNAME is a user-provided Java class\n",
      "\n",
      "  OPTIONS is none or any of:\n",
      "\n",
      "buildpaths                       attempt to add class files from build tree\n",
      "--config dir                     Hadoop config directory\n",
      "--debug                          turn on shell script debug mode\n",
      "--help                           usage information\n",
      "hostnames list[,of,host,names]   hosts to use in worker mode\n",
      "hosts filename                   list of hosts to use in worker mode\n",
      "loglevel level                   set the log4j level for this command\n",
      "workers                          turn on worker mode\n",
      "\n",
      "  SUBCOMMAND is one of:\n",
      "\n",
      "\n",
      "    Admin Commands:\n",
      "\n",
      "daemonlog     get/set the log level for each daemon\n",
      "\n",
      "    Client Commands:\n",
      "\n",
      "archive       create a Hadoop archive\n",
      "checknative   check native Hadoop and compression libraries availability\n",
      "classpath     prints the class path needed to get the Hadoop jar and the required libraries\n",
      "conftest      validate configuration XML files\n",
      "credential    interact with credential providers\n",
      "distch        distributed metadata changer\n",
      "distcp        copy file or directories recursively\n",
      "dtutil        operations related to delegation tokens\n",
      "envvars       display computed Hadoop environment variables\n",
      "fs            run a generic filesystem user client\n",
      "gridmix       submit a mix of synthetic job, modeling a profiled from production load\n",
      "jar <jar>     run a jar file. NOTE: please use \"yarn jar\" to launch YARN applications, not this\n",
      "              command.\n",
      "jnipath       prints the java.library.path\n",
      "kdiag         Diagnose Kerberos Problems\n",
      "kerbname      show auth_to_local principal conversion\n",
      "key           manage keys via the KeyProvider\n",
      "rumenfolder   scale a rumen input trace\n",
      "rumentrace    convert logs into a rumen trace\n",
      "s3guard       S3 Commands\n",
      "trace         view and modify Hadoop tracing settings\n",
      "version       print the version\n",
      "\n",
      "    Daemon Commands:\n",
      "\n",
      "kms           run KMS, the Key Management Server\n",
      "registrydns   run the registry DNS server\n",
      "\n",
      "SUBCOMMAND may print help when invoked w/o parameters or with -h.\n"
     ]
    }
   ],
   "source": [
    "!/usr/local/hadoop-3.3.6/bin/hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbtSzu3E0lzs"
   },
   "source": [
    "Una de las formas tradicionales de asegurarnos que un ambiente de Hadoop recién instalado funciona correctamente, es ejecutando el *jar* de ejemplos *map-reduce* incluido con toda instalación de hadoop (*hadoop-mapreduce-examples.jar*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHXdP_vg0z8r"
   },
   "source": [
    "1. Creamos un directorio llamado input en nuestro directorio de inicio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1705940032652,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "uI-YBPIzcBCA",
    "outputId": "2887a6f7-61aa-464a-8499-e9139a66cc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/input’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMfgeMdb06gK"
   },
   "source": [
    "2. Copiamos los archivos de configuración (los xml) de Hadoop para usar esos archivos como nuestros datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1705940032652,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "6DuDJIsPcA98",
    "outputId": "fbc01e5e-00fc-44a6-daae-600ee571df4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capacity-scheduler.xml\thadoop-policy.xml  hdfs-site.xml    kms-acls.xml  mapred-site.xml\n",
      "core-site.xml\t\thdfs-rbf-site.xml  httpfs-site.xml  kms-site.xml  yarn-site.xml\n"
     ]
    }
   ],
   "source": [
    "!cp /usr/local/hadoop-3.3.6/etc/hadoop/*.xml ~/input\n",
    "!ls ~/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE5GNAld18M0"
   },
   "source": [
    "3. Ejecutamos **hadoop jar** con el fin de ejecutar uno de los ejemplos por defecto, en este caso el *grep* que busca expresiones regulares dentro de los ficheros que le especifiquemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4lTSJcJ1cJx"
   },
   "source": [
    "- **/usr/local/hadoop/bin/hadoop** Es el directorio donde esta el ejecutable de hadoop en el sistema.\n",
    "- **jar** Le indica a hadoop que deseamos ejecutar una aplicacion empaquetada de Java. (Jar)\n",
    "- **/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.ja**r Es la ruta donde esta el Jar que deseamos ejecutar. La versión del jar depende de la versión de hadoop instalada.\n",
    "\n",
    "- grep Es un parámetro de los muchos que se le pueden pasar al Jar de ejemplos que trae Hadoop. grep sirve para encontrar y contar ocurrencias de strings haciendo uso de expresiones regulares.\n",
    "\n",
    "- **~/input** El directorio de entrada. Es donde el programa va a buscar los archivos de entrada a la tarea de map-reduce. Aquí copiamos unos archivos de prueba en un comando anterior.\n",
    "- **~/grep_example** El directorio de salida. Es donde el programa va a escribir el resultado de la corrida de la aplicación. En este caso, la cantidad de veces que la palabra del parámetro siguiente, aparece en los archivos de entrada.\n",
    "- **‘allowed[.]*’** Es la expresión regular que deseamos buscar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8848,
     "status": "ok",
     "timestamp": 1705940053621,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "RZi5zOGKyySH",
    "outputId": "b0416833-3554-4bfb-a3a7-1ce922919eed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 16:14:07,487 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2024-01-22 16:14:07,964 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-01-22 16:14:07,964 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2024-01-22 16:14:08,584 INFO input.FileInputFormat: Total input files to process : 10\n",
      "2024-01-22 16:14:08,674 INFO mapreduce.JobSubmitter: number of splits:10\n",
      "2024-01-22 16:14:09,265 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1264866328_0001\n",
      "2024-01-22 16:14:09,266 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-01-22 16:14:09,772 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-01-22 16:14:09,773 INFO mapreduce.Job: Running job: job_local1264866328_0001\n",
      "2024-01-22 16:14:09,783 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-01-22 16:14:09,815 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:09,817 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:09,817 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:09,824 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-01-22 16:14:10,035 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-01-22 16:14:10,036 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000000_0\n",
      "2024-01-22 16:14:10,127 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,128 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,128 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,178 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,185 INFO mapred.MapTask: Processing split: file:/root/input/hadoop-policy.xml:0+11765\n",
      "2024-01-22 16:14:10,290 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,290 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,290 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,290 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,291 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,296 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,320 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,321 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,321 INFO mapred.MapTask: Spilling map output\n",
      "2024-01-22 16:14:10,321 INFO mapred.MapTask: bufstart = 0; bufend = 374; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,321 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214312(104857248); length = 85/6553600\n",
      "2024-01-22 16:14:10,338 INFO mapred.MapTask: Finished spill 0\n",
      "2024-01-22 16:14:10,364 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,369 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,369 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000000_0' done.\n",
      "2024-01-22 16:14:10,379 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=294292\n",
      "\t\tFILE: Number of bytes written=921593\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=275\n",
      "\t\tMap output records=22\n",
      "\t\tMap output bytes=374\n",
      "\t\tMap output materialized bytes=25\n",
      "\t\tInput split bytes=99\n",
      "\t\tCombine input records=22\n",
      "\t\tCombine output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=432013312\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=11765\n",
      "2024-01-22 16:14:10,379 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000000_0\n",
      "2024-01-22 16:14:10,380 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000001_0\n",
      "2024-01-22 16:14:10,382 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,382 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,382 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,382 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,388 INFO mapred.MapTask: Processing split: file:/root/input/capacity-scheduler.xml:0+9213\n",
      "2024-01-22 16:14:10,435 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,435 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,435 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,437 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,437 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,438 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,460 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,465 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,465 INFO mapred.MapTask: Spilling map output\n",
      "2024-01-22 16:14:10,465 INFO mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,465 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2024-01-22 16:14:10,468 INFO mapred.MapTask: Finished spill 0\n",
      "2024-01-22 16:14:10,478 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,485 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,485 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000001_0' done.\n",
      "2024-01-22 16:14:10,486 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=304497\n",
      "\t\tFILE: Number of bytes written=921649\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=244\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=16\n",
      "\t\tMap output materialized bytes=24\n",
      "\t\tInput split bytes=104\n",
      "\t\tCombine input records=1\n",
      "\t\tCombine output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=16\n",
      "\t\tTotal committed heap usage (bytes)=432013312\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=9213\n",
      "2024-01-22 16:14:10,486 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000001_0\n",
      "2024-01-22 16:14:10,486 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000002_0\n",
      "2024-01-22 16:14:10,489 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,489 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,489 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,490 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,495 INFO mapred.MapTask: Processing split: file:/root/input/kms-acls.xml:0+3518\n",
      "2024-01-22 16:14:10,554 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,554 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,554 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,554 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,554 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,557 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,563 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,569 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,579 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000002_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,581 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,581 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000002_0' done.\n",
      "2024-01-22 16:14:10,582 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000002_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=309007\n",
      "\t\tFILE: Number of bytes written=921687\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=135\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=94\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=15\n",
      "\t\tTotal committed heap usage (bytes)=432013312\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=3518\n",
      "2024-01-22 16:14:10,582 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000002_0\n",
      "2024-01-22 16:14:10,582 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000003_0\n",
      "2024-01-22 16:14:10,584 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,584 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,584 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,584 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,586 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-site.xml:0+775\n",
      "2024-01-22 16:14:10,625 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,626 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,626 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,626 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,626 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,627 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,644 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,651 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,659 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000003_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,661 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,662 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000003_0' done.\n",
      "2024-01-22 16:14:10,663 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000003_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=310774\n",
      "\t\tFILE: Number of bytes written=921725\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=21\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=95\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=775\n",
      "2024-01-22 16:14:10,663 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000003_0\n",
      "2024-01-22 16:14:10,664 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000004_0\n",
      "2024-01-22 16:14:10,665 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,665 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,665 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,666 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,671 INFO mapred.MapTask: Processing split: file:/root/input/core-site.xml:0+774\n",
      "2024-01-22 16:14:10,722 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,723 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,723 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,723 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,723 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,724 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,727 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,728 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,732 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000004_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,734 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,735 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000004_0' done.\n",
      "2024-01-22 16:14:10,735 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000004_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=312540\n",
      "\t\tFILE: Number of bytes written=921763\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=20\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=95\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=774\n",
      "2024-01-22 16:14:10,735 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000004_0\n",
      "2024-01-22 16:14:10,735 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000005_0\n",
      "2024-01-22 16:14:10,740 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,740 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,740 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,742 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,747 INFO mapred.MapTask: Processing split: file:/root/input/mapred-site.xml:0+758\n",
      "2024-01-22 16:14:10,785 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,785 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,785 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,785 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,786 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,789 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,800 INFO mapreduce.Job: Job job_local1264866328_0001 running in uber mode : false\n",
      "2024-01-22 16:14:10,805 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2024-01-22 16:14:10,820 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,821 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,832 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000005_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,837 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,837 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000005_0' done.\n",
      "2024-01-22 16:14:10,839 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000005_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=314290\n",
      "\t\tFILE: Number of bytes written=921801\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=21\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=97\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=5\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=758\n",
      "2024-01-22 16:14:10,839 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000005_0\n",
      "2024-01-22 16:14:10,839 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000006_0\n",
      "2024-01-22 16:14:10,841 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,841 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,841 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,842 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,844 INFO mapred.MapTask: Processing split: file:/root/input/yarn-site.xml:0+690\n",
      "2024-01-22 16:14:10,860 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,861 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,861 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,861 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,861 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,861 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,866 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,866 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,870 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000006_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,872 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,873 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000006_0' done.\n",
      "2024-01-22 16:14:10,873 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000006_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=315460\n",
      "\t\tFILE: Number of bytes written=921839\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=19\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=95\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=690\n",
      "2024-01-22 16:14:10,873 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000006_0\n",
      "2024-01-22 16:14:10,873 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000007_0\n",
      "2024-01-22 16:14:10,879 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,879 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,879 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,879 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,883 INFO mapred.MapTask: Processing split: file:/root/input/hdfs-rbf-site.xml:0+683\n",
      "2024-01-22 16:14:10,913 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,913 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,913 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,913 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,913 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,920 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,925 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,926 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,935 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000007_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,938 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,948 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000007_0' done.\n",
      "2024-01-22 16:14:10,949 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000007_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=316623\n",
      "\t\tFILE: Number of bytes written=921877\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=20\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=99\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=5\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=683\n",
      "2024-01-22 16:14:10,949 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000007_0\n",
      "2024-01-22 16:14:10,949 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000008_0\n",
      "2024-01-22 16:14:10,953 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,953 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,953 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,954 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,960 INFO mapred.MapTask: Processing split: file:/root/input/kms-site.xml:0+682\n",
      "2024-01-22 16:14:10,982 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:10,982 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:10,982 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:10,983 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:10,983 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:10,984 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:10,988 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:10,989 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:10,993 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000008_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:10,995 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:10,995 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000008_0' done.\n",
      "2024-01-22 16:14:10,995 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000008_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=317785\n",
      "\t\tFILE: Number of bytes written=921915\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=20\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=94\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=682\n",
      "2024-01-22 16:14:10,995 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000008_0\n",
      "2024-01-22 16:14:10,996 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_m_000009_0\n",
      "2024-01-22 16:14:10,997 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:10,997 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:10,997 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:10,998 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:10,999 INFO mapred.MapTask: Processing split: file:/root/input/httpfs-site.xml:0+620\n",
      "2024-01-22 16:14:11,035 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:11,035 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:11,035 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:11,035 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:11,035 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:11,037 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:11,047 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:11,047 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:11,056 INFO mapred.Task: Task:attempt_local1264866328_0001_m_000009_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:11,060 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:11,060 INFO mapred.Task: Task 'attempt_local1264866328_0001_m_000009_0' done.\n",
      "2024-01-22 16:14:11,061 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_m_000009_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=318885\n",
      "\t\tFILE: Number of bytes written=921953\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=17\n",
      "\t\tMap output records=0\n",
      "\t\tMap output bytes=0\n",
      "\t\tMap output materialized bytes=6\n",
      "\t\tInput split bytes=97\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=5\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=620\n",
      "2024-01-22 16:14:11,061 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_m_000009_0\n",
      "2024-01-22 16:14:11,061 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-01-22 16:14:11,065 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-01-22 16:14:11,066 INFO mapred.LocalJobRunner: Starting task: attempt_local1264866328_0001_r_000000_0\n",
      "2024-01-22 16:14:11,077 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:11,077 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:11,077 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:11,077 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:11,084 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f7e4ccc\n",
      "2024-01-22 16:14:11,085 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-01-22 16:14:11,110 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-22 16:14:11,115 INFO reduce.EventFetcher: attempt_local1264866328_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-22 16:14:11,163 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000001_0 decomp: 20 len: 24 to MEMORY\n",
      "2024-01-22 16:14:11,167 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local1264866328_0001_m_000001_0\n",
      "2024-01-22 16:14:11,172 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20\n",
      "2024-01-22 16:14:11,182 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000007_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,184 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000007_0\n",
      "2024-01-22 16:14:11,184 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 2, commitMemory -> 20, usedMemory ->22\n",
      "2024-01-22 16:14:11,189 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000004_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,195 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000004_0\n",
      "2024-01-22 16:14:11,195 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 3, commitMemory -> 22, usedMemory ->24\n",
      "2024-01-22 16:14:11,197 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000003_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,200 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000003_0\n",
      "2024-01-22 16:14:11,200 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 4, commitMemory -> 24, usedMemory ->26\n",
      "2024-01-22 16:14:11,204 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000000_0 decomp: 21 len: 25 to MEMORY\n",
      "2024-01-22 16:14:11,209 INFO reduce.InMemoryMapOutput: Read 21 bytes from map-output for attempt_local1264866328_0001_m_000000_0\n",
      "2024-01-22 16:14:11,210 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 21, inMemoryMapOutputs.size() -> 5, commitMemory -> 26, usedMemory ->47\n",
      "2024-01-22 16:14:11,212 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000009_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,213 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000009_0\n",
      "2024-01-22 16:14:11,214 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 6, commitMemory -> 47, usedMemory ->49\n",
      "2024-01-22 16:14:11,215 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000006_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,218 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000006_0\n",
      "2024-01-22 16:14:11,219 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 7, commitMemory -> 49, usedMemory ->51\n",
      "2024-01-22 16:14:11,225 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000005_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,225 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000005_0\n",
      "2024-01-22 16:14:11,227 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 8, commitMemory -> 51, usedMemory ->53\n",
      "2024-01-22 16:14:11,229 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000002_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,230 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000002_0\n",
      "2024-01-22 16:14:11,231 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 9, commitMemory -> 53, usedMemory ->55\n",
      "2024-01-22 16:14:11,236 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1264866328_0001_m_000008_0 decomp: 2 len: 6 to MEMORY\n",
      "2024-01-22 16:14:11,238 INFO reduce.InMemoryMapOutput: Read 2 bytes from map-output for attempt_local1264866328_0001_m_000008_0\n",
      "2024-01-22 16:14:11,239 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 10, commitMemory -> 55, usedMemory ->57\n",
      "2024-01-22 16:14:11,240 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-01-22 16:14:11,241 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
      "2024-01-22 16:14:11,241 INFO reduce.MergeManagerImpl: finalMerge called with 10 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-22 16:14:11,253 INFO mapred.Merger: Merging 10 sorted segments\n",
      "2024-01-22 16:14:11,254 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 20 bytes\n",
      "2024-01-22 16:14:11,256 INFO reduce.MergeManagerImpl: Merged 10 segments, 57 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-22 16:14:11,257 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n",
      "2024-01-22 16:14:11,258 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-22 16:14:11,258 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-01-22 16:14:11,259 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
      "2024-01-22 16:14:11,259 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
      "2024-01-22 16:14:11,288 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-01-22 16:14:11,290 INFO mapred.Task: Task:attempt_local1264866328_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:11,294 INFO mapred.LocalJobRunner: 10 / 10 copied.\n",
      "2024-01-22 16:14:11,295 INFO mapred.Task: Task attempt_local1264866328_0001_r_000000_0 is allowed to commit now\n",
      "2024-01-22 16:14:11,297 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1264866328_0001_r_000000_0' to file:/content/grep-temp-1035124850\n",
      "2024-01-22 16:14:11,298 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-01-22 16:14:11,298 INFO mapred.Task: Task 'attempt_local1264866328_0001_r_000000_0' done.\n",
      "2024-01-22 16:14:11,299 INFO mapred.Task: Final Counters for attempt_local1264866328_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=319345\n",
      "\t\tFILE: Number of bytes written=922143\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=97\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=10\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=147\n",
      "2024-01-22 16:14:11,299 INFO mapred.LocalJobRunner: Finishing task: attempt_local1264866328_0001_r_000000_0\n",
      "2024-01-22 16:14:11,299 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-01-22 16:14:11,811 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-01-22 16:14:11,812 INFO mapreduce.Job: Job job_local1264866328_0001 completed successfully\n",
      "2024-01-22 16:14:11,831 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=3433498\n",
      "\t\tFILE: Number of bytes written=10139945\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=792\n",
      "\t\tMap output records=23\n",
      "\t\tMap output bytes=390\n",
      "\t\tMap output materialized bytes=97\n",
      "\t\tInput split bytes=969\n",
      "\t\tCombine input records=23\n",
      "\t\tCombine output records=2\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=97\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=10\n",
      "\t\tGC time elapsed (ms)=56\n",
      "\t\tTotal committed heap usage (bytes)=5448400896\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=29478\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=147\n",
      "2024-01-22 16:14:11,892 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-01-22 16:14:11,907 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2024-01-22 16:14:11,911 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "2024-01-22 16:14:11,958 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local24982409_0002\n",
      "2024-01-22 16:14:11,959 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-01-22 16:14:12,151 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-01-22 16:14:12,152 INFO mapreduce.Job: Running job: job_local24982409_0002\n",
      "2024-01-22 16:14:12,154 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-01-22 16:14:12,155 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:12,155 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:12,155 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:12,155 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-01-22 16:14:12,160 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-01-22 16:14:12,160 INFO mapred.LocalJobRunner: Starting task: attempt_local24982409_0002_m_000000_0\n",
      "2024-01-22 16:14:12,161 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:12,161 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:12,161 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:12,162 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:12,167 INFO mapred.MapTask: Processing split: file:/content/grep-temp-1035124850/part-r-00000:0+135\n",
      "2024-01-22 16:14:12,184 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-01-22 16:14:12,184 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-01-22 16:14:12,184 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-01-22 16:14:12,184 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-01-22 16:14:12,185 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-01-22 16:14:12,187 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-01-22 16:14:12,197 INFO mapred.LocalJobRunner: \n",
      "2024-01-22 16:14:12,198 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-01-22 16:14:12,198 INFO mapred.MapTask: Spilling map output\n",
      "2024-01-22 16:14:12,198 INFO mapred.MapTask: bufstart = 0; bufend = 33; bufvoid = 104857600\n",
      "2024-01-22 16:14:12,198 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600\n",
      "2024-01-22 16:14:12,200 INFO mapred.MapTask: Finished spill 0\n",
      "2024-01-22 16:14:12,204 INFO mapred.Task: Task:attempt_local24982409_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:12,206 INFO mapred.LocalJobRunner: map\n",
      "2024-01-22 16:14:12,206 INFO mapred.Task: Task 'attempt_local24982409_0002_m_000000_0' done.\n",
      "2024-01-22 16:14:12,207 INFO mapred.Task: Final Counters for attempt_local24982409_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=601007\n",
      "\t\tFILE: Number of bytes written=1835289\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=2\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=33\n",
      "\t\tMap output materialized bytes=43\n",
      "\t\tInput split bytes=112\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=147\n",
      "2024-01-22 16:14:12,208 INFO mapred.LocalJobRunner: Finishing task: attempt_local24982409_0002_m_000000_0\n",
      "2024-01-22 16:14:12,208 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-01-22 16:14:12,209 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-01-22 16:14:12,213 INFO mapred.LocalJobRunner: Starting task: attempt_local24982409_0002_r_000000_0\n",
      "2024-01-22 16:14:12,216 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-01-22 16:14:12,216 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-01-22 16:14:12,216 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-01-22 16:14:12,216 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-01-22 16:14:12,216 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@26d70fb1\n",
      "2024-01-22 16:14:12,220 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-01-22 16:14:12,222 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-01-22 16:14:12,223 INFO reduce.EventFetcher: attempt_local24982409_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-01-22 16:14:12,232 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local24982409_0002_m_000000_0 decomp: 39 len: 43 to MEMORY\n",
      "2024-01-22 16:14:12,233 INFO reduce.InMemoryMapOutput: Read 39 bytes from map-output for attempt_local24982409_0002_m_000000_0\n",
      "2024-01-22 16:14:12,233 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->39\n",
      "2024-01-22 16:14:12,234 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-01-22 16:14:12,236 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-01-22 16:14:12,236 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-01-22 16:14:12,237 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-01-22 16:14:12,238 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
      "2024-01-22 16:14:12,240 INFO reduce.MergeManagerImpl: Merged 1 segments, 39 bytes to disk to satisfy reduce memory limit\n",
      "2024-01-22 16:14:12,240 INFO reduce.MergeManagerImpl: Merging 1 files, 43 bytes from disk\n",
      "2024-01-22 16:14:12,241 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-01-22 16:14:12,241 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-01-22 16:14:12,241 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 29 bytes\n",
      "2024-01-22 16:14:12,242 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-01-22 16:14:12,246 INFO mapred.Task: Task:attempt_local24982409_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-01-22 16:14:12,249 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-01-22 16:14:12,249 INFO mapred.Task: Task attempt_local24982409_0002_r_000000_0 is allowed to commit now\n",
      "2024-01-22 16:14:12,251 INFO output.FileOutputCommitter: Saved output of task 'attempt_local24982409_0002_r_000000_0' to file:/root/grep_example\n",
      "2024-01-22 16:14:12,252 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-01-22 16:14:12,252 INFO mapred.Task: Task 'attempt_local24982409_0002_r_000000_0' done.\n",
      "2024-01-22 16:14:12,253 INFO mapred.Task: Final Counters for attempt_local24982409_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=601125\n",
      "\t\tFILE: Number of bytes written=1835366\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=43\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=519045120\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=34\n",
      "2024-01-22 16:14:12,253 INFO mapred.LocalJobRunner: Finishing task: attempt_local24982409_0002_r_000000_0\n",
      "2024-01-22 16:14:12,253 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-01-22 16:14:13,152 INFO mapreduce.Job: Job job_local24982409_0002 running in uber mode : false\n",
      "2024-01-22 16:14:13,153 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-01-22 16:14:13,153 INFO mapreduce.Job: Job job_local24982409_0002 completed successfully\n",
      "2024-01-22 16:14:13,156 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1202132\n",
      "\t\tFILE: Number of bytes written=3670655\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=2\n",
      "\t\tMap output records=2\n",
      "\t\tMap output bytes=33\n",
      "\t\tMap output materialized bytes=43\n",
      "\t\tInput split bytes=112\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=43\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=1038090240\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=147\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=34\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/local/hadoop-3.3.6/bin/hadoop jar \\\n",
    "  /usr/local/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar \\\n",
    "  grep ~/input ~/grep_example 'allowed[.]*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5XVX6Zz1Phd"
   },
   "source": [
    "Los resultados se almacenan en el directorio de salida (~/grep_example/) y se pueden verificar ejecutando *cat* el directorio de salida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1705940059167,
     "user": {
      "displayName": "Miguel Ronda",
      "userId": "13437494457168354933"
     },
     "user_tz": -60
    },
    "id": "mtr0xWbfcA5J",
    "outputId": "b1a61a95-4e6c-41d1-d3ab-aaec606ef80d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\tallowed.\n",
      "1\tallowed\n"
     ]
    }
   ],
   "source": [
    "!cat ~/grep_example/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDOTIOLwrohQ"
   },
   "source": [
    "## Ejercicio\n",
    "\n",
    "Es interesante probar otros ejemplos contenidos en el jar de ejemplos de hadoop.\n",
    "[Hadoop Map Reduce Examples](http://svn.apache.org/viewvc/hadoop/common/trunk/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1WwvQNgjXNHrBjreSm-_6rrYKHJv91MuT",
     "timestamp": 1705940978818
    },
    {
     "file_id": "1m19NE_krUVngaZ-BtS_wSYM8Gv-THg8l",
     "timestamp": 1633273994007
    },
    {
     "file_id": "1CPXjJ96Rb8UQ4OXBSf6OOtm18ZsMiPXs",
     "timestamp": 1632989552829
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
