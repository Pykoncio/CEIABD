{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch, Conceptos básicos.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "* Es un framework enfocado en *deep learning*. \n",
    "* Es el más utilizado en los parpers de IA en general y deep learning en particular.\n",
    "* Comparte mucha nomenclatura con NumPy.\n",
    "\n",
    "Hay librerías que extienden las funcionalidades de PyTorch en dominios específicos:\n",
    "\n",
    "* `torchvision`\n",
    "* `torchaudio`\n",
    "* `torchtext`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.1+cpu'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación a partir de una lista\n",
    "\n",
    "lista = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "tensor1 = torch.tensor(lista)\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creación a partir de un array de numpy\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]], dtype=np.int64)\n",
    "\n",
    "tensor2 = torch.from_numpy(a)\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensiones\n",
    "\n",
    "tensor1.shape, tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de dato base\n",
    "\n",
    "tensor1.dtype, tensor2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uso de CPU o GPU\n",
    "\n",
    "tensor1.device, tensor2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de elementos\n",
    "\n",
    "tensor1.numel(), tensor2.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.strided, torch.strided)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipo de almacenamiento en memoria\n",
    "\n",
    "tensor1.layout, tensor2.layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones con tensores\n",
    "\n",
    "Estos tensores, a diferencia de TensorFlow, si son mutables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  4,  6],\n",
       "         [ 8, 10, 12]]),\n",
       " tensor([[0, 0, 0],\n",
       "         [0, 0, 0]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suma o resta (deben tener las mismas dimensiones)\n",
    "\n",
    "tensor1 + tensor2, tensor1 - tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  4,  9],\n",
       "         [16, 25, 36]]),\n",
       " tensor([[100, 200, 300],\n",
       "         [400, 500, 600]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación elemento a elemento\n",
    "tensor1 * tensor2, tensor1 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14, 32],\n",
       "        [32, 77]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiplicación matricial\n",
    "torch.matmul(tensor1, tensor2.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(21), tensor(21))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumatorio\n",
    "tensor1.sum(), tensor2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6), tensor(1), tensor(3.5000))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Máximo, mínimo y media\n",
    "\n",
    "tensor1.max(), tensor1.min(), tensor1.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la librería correspondiente a redes neuronales\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de una capa lineal para la entrada\n",
    "input_layer = nn.Linear(in_features=3, out_features=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7830, -0.2038,  0.2291]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.tensor([[0.783, -0.2038, 0.2291]])\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1094, -0.0023]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = input_layer(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.4995, -0.1653, -0.1989],\n",
       "         [-0.3875,  0.0589,  0.3095]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2936, 0.2422], requires_grad=True))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pesos y sesgos de la capa\n",
    "input_layer.weight, input_layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1094, -0.0023]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio\n",
    "# Comprueba que operaciones matemáticas se están haciendo en la capa\n",
    "\n",
    "output_manual = torch.matmul(input_data, input_layer.weight.T) + input_layer.bias\n",
    "output_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red neuronal con varias capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 6),\n",
    "    nn.Linear(6, 18),\n",
    "    nn.Linear(18, 20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1091, -1.1388,  1.2262,  0.6285,  0.9155,  0.0601,  0.5424,  0.8952,\n",
       "         -0.6316, -0.6076]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = torch.randn(1, 10)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1207, -0.0743, -0.0674, -0.1834,  0.7042, -0.1684, -0.3769, -0.3614,\n",
       "          0.7647, -0.5893, -0.3678, -0.7546,  0.4843, -0.1544,  0.5831,  0.1492,\n",
       "         -0.2590,  0.2143, -0.0215, -0.1611]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos el tensor de entrada a la red neuronal\n",
    "\n",
    "output_tensor = model(input_data)\n",
    "output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función de activación\n",
    "\n",
    "En PyTorch, a diferencia de TensorFlow, las funciones de activación no se suelen especificar como un parámetro en las capas. En su lugar, se definen explícitamente como capas separadas en la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8082, -0.6716, -0.7368,  1.6353,  1.0576, -1.2473],\n",
       "        [-1.0543,  0.7354,  0.4588,  0.2235,  0.4273,  1.5841],\n",
       "        [-0.1515, -0.4123, -0.3217,  1.3911,  0.9793,  0.1941],\n",
       "        [ 0.7246,  0.1325, -0.4546,  0.1099,  0.1897,  0.7584]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = torch.randn((4, 6))\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3083, 0.3381, 0.3237, 0.8369, 0.7422, 0.2232],\n",
       "        [0.2584, 0.6760, 0.6127, 0.5557, 0.6052, 0.8298],\n",
       "        [0.4622, 0.3984, 0.4203, 0.8008, 0.7270, 0.5484],\n",
       "        [0.6736, 0.5331, 0.3883, 0.5275, 0.5473, 0.6810]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid = nn.Sigmoid()\n",
    "sigmoid(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 1.6353, 1.0576, 0.0000],\n",
       "        [0.0000, 0.7354, 0.4588, 0.2235, 0.4273, 1.5841],\n",
       "        [0.0000, 0.0000, 0.0000, 1.3911, 0.9793, 0.1941],\n",
       "        [0.7246, 0.1325, 0.0000, 0.1099, 0.1897, 0.7584]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "relu(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alfre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0458, 0.0525, 0.0492, 0.5272, 0.2958, 0.0295],\n",
       "        [0.0298, 0.1787, 0.1355, 0.1071, 0.1313, 0.4175],\n",
       "        [0.0847, 0.0653, 0.0715, 0.3963, 0.2625, 0.1197],\n",
       "        [0.2487, 0.1376, 0.0765, 0.1345, 0.1456, 0.2572]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax()\n",
    "softmax(tensor3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=6, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=6, out_features=18, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=18, out_features=20, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Funciones de activación en una red neuronal\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 18),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(18, 20),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
