{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios básicos de NLP: Tokenización y análisis de texto\n",
    "\n",
    "Ejercicio realizado por:\n",
    "\n",
    "* Nombre completo del alumno/a 1\n",
    "* Nombre completo del alumno/a 2\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "Se debe cambiar RRR por una expresión regular y FFF por el nombre de una instrucción o método.\n",
    "\n",
    "Expresiones regulares con Python:\n",
    "\n",
    "* <https://www.w3schools.com/python/python_regex.asp>\n",
    "* <https://realpython.com/regex-python/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # Para trabajar con expresiones regulares\n",
    "from collections import Counter # Para contar elementos de una colección"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oraciones:\n",
      "1. El perro corre rápidamente por el parque.\n",
      "2. Los niños juegan felices.\n",
      "\n",
      "Palabras:\n",
      "['el', 'perro', 'corre', 'rápidamente', 'por', 'el', 'parque', 'los', 'niños', 'juegan', 'felices']\n"
     ]
    }
   ],
   "source": [
    "def tokeniza_oraciones(texto):\n",
    "    \"\"\"Divide el texto en oraciones.\"\"\"\n",
    "    # Ejercicio 1\n",
    "    # Patrones de fin de oración: punto seguido de espacio y mayúscula\n",
    "    # Pista: buscar qué significan \"lookbehind\" y \"lookahead\"\n",
    "    return re.split(r'RRR', texto)\n",
    "\n",
    "def tokeniza_palabras(texto):\n",
    "    \"\"\"Divide el texto en palabras.\"\"\"\n",
    "    # Ejercicio 2\n",
    "    # Elimina signos de puntuación\n",
    "    texto = re.sub(r'RRR', ' ', texto)\n",
    "    # Ejercicio 3\n",
    "    # Pasa todo a minúsculas y trocea para obtener las palabras\n",
    "    return texto.FFF().FFF()\n",
    "\n",
    "# Ejemplo\n",
    "texto = \"El perro corre rápidamente por el parque. Los niños juegan felices.\"\n",
    "\n",
    "print(\"Oraciones:\")\n",
    "# Ejercicio 4\n",
    "# Extrae las oraciones\n",
    "for i, oracion in enumerate(FFF(texto), 1):\n",
    "    print(f\"{i}. {oracion}\")\n",
    "\n",
    "print(\"\\nPalabras:\")\n",
    "# Ejercicio 5\n",
    "# Extrae las palabras\n",
    "palabras = FFF(texto)\n",
    "print(palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análisis del texto:\n",
      "Número de oraciones: 3\n",
      "Número de palabras: 31\n",
      "Número de caracteres: 211\n",
      "Palabras únicas: 25\n",
      "\n",
      "Palabras más frecuentes:\n",
      "  el: 3\n",
      "  análisis: 2\n",
      "  de: 2\n",
      "  texto: 2\n",
      "  del: 2\n"
     ]
    }
   ],
   "source": [
    "def analiza_texto(texto):\n",
    "    \"\"\"Realiza un análisis básico del texto.\"\"\"\n",
    "    # Tokenización\n",
    "    oraciones = tokeniza_oraciones(texto)\n",
    "    palabras = tokeniza_palabras(texto)\n",
    "\n",
    "    # Análisis\n",
    "    num_oraciones = len(oraciones)\n",
    "    num_palabras = len(palabras)\n",
    "    num_caracteres = len(texto)\n",
    "    # Ejercicio 6\n",
    "    palabras_unicas = len(FFF(palabras))\n",
    "    # Ejercicio 7\n",
    "    frecuencia_palabras = FFF(palabras)\n",
    "\n",
    "    # Resultados\n",
    "    print(f\"Número de oraciones: {num_oraciones}\")\n",
    "    print(f\"Número de palabras: {num_palabras}\")\n",
    "    print(f\"Número de caracteres: {num_caracteres}\")\n",
    "    print(f\"Palabras únicas: {palabras_unicas}\")\n",
    "    print(\"\\nPalabras más frecuentes:\")\n",
    "    for palabra, freq in frecuencia_palabras.most_common(5):\n",
    "        print(f\"  {palabra}: {freq}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "texto_ejemplo = \"\"\"\n",
    "El análisis de texto es una parte fundamental del procesamiento de lenguaje natural. \n",
    "Los textos contienen mucha información que podemos extraer. \n",
    "El análisis nos permite entender mejor el contenido del texto.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Análisis del texto:\")\n",
    "analiza_texto(texto_ejemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Búsqueda de patrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patrones encontrados:\n",
      "\n",
      "Emails:\n",
      "  - usuario@ejemplo.com\n",
      "\n",
      "Fechas:\n",
      "  - 25/10/2024\n",
      "\n",
      "Urls:\n",
      "  - https://www.ejemplo.com\n",
      "\n",
      "Hashtags:\n",
      "  - #python\n",
      "  - #nlp\n",
      "  - #procesamiento\n"
     ]
    }
   ],
   "source": [
    "def encuentra_patrones(texto):\n",
    "    \"\"\"Encuentra patrones específicos en el texto.\"\"\"\n",
    "    # Patrones de ejemplo\n",
    "    patrones = {\n",
    "        # Ejercicio 8\n",
    "        'emails': r'RRR',\n",
    "        # Ejercicio 9\n",
    "        'fechas': r'RRR',\n",
    "        # Ejercicio 10\n",
    "        'urls': r'RRR',\n",
    "        # Ejercicio 11\n",
    "        'hashtags': r'RRR'\n",
    "    }\n",
    "\n",
    "    resultados = {}\n",
    "    for nombre, patron in patrones.items():\n",
    "        resultados[nombre] = re.findall(patron, texto)\n",
    "\n",
    "    return resultados\n",
    "\n",
    "# Ejemplo de uso\n",
    "texto_patrones = \"\"\"\n",
    "Contacto: usuario@ejemplo.com\n",
    "Fecha: 25/10/2024\n",
    "Web: https://www.ejemplo.com\n",
    "Tags: #python #nlp #procesamiento\n",
    "\"\"\"\n",
    "\n",
    "print(\"Patrones encontrados:\")\n",
    "patrones = encuentra_patrones(texto_patrones)\n",
    "for tipo, encontrados in patrones.items():\n",
    "    if encontrados:\n",
    "        print(f\"\\n{tipo.capitalize()}:\")\n",
    "        for item in encontrados:\n",
    "            print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estadísticas del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas del texto:\n",
      "Promedio de palabras por oración: 8.0\n",
      "Oración más larga: 13 palabras\n",
      "Oración más corta: 3 palabras\n",
      "Total de palabras: 32\n",
      "Total de oraciones: 4\n"
     ]
    }
   ],
   "source": [
    "def estadisticas_texto(texto):\n",
    "    \"\"\"Calcula estadísticas detalladas del texto.\"\"\"\n",
    "    oraciones = tokeniza_oraciones(texto)\n",
    "    palabras_por_oracion = [len(tokeniza_palabras(oracion)) for oracion in oraciones]\n",
    "    \n",
    "    stats = {\n",
    "        # Ejercicio 12\n",
    "        'longitud_promedio_oracion': FFF(palabras_por_oracion) / FFF(palabras_por_oracion),\n",
    "        # Ejercicio 13\n",
    "        'oracion_mas_larga': FFF(palabras_por_oracion),\n",
    "        # Ejercicio 14\n",
    "        'oracion_mas_corta': FFF(palabras_por_oracion),\n",
    "        # Ejercicio 15\n",
    "        'palabras_totales': FFF(palabras_por_oracion),\n",
    "        # Ejercicio 16\n",
    "        'oraciones_totales': FFF(oraciones)\n",
    "    }\n",
    "    \n",
    "    print(\"Estadísticas del texto:\")\n",
    "    print(f\"Promedio de palabras por oración: {stats['longitud_promedio_oracion']:.1f}\")\n",
    "    print(f\"Oración más larga: {stats['oracion_mas_larga']} palabras\")\n",
    "    print(f\"Oración más corta: {stats['oracion_mas_corta']} palabras\")\n",
    "    print(f\"Total de palabras: {stats['palabras_totales']}\")\n",
    "    print(f\"Total de oraciones: {stats['oraciones_totales']}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "texto_estadisticas = \"\"\"\n",
    "Este es un ejemplo de texto para análisis. \n",
    "Contiene varias oraciones de diferente longitud y complejidad. \n",
    "Algunas son cortas. \n",
    "Otras oraciones son más largas y contienen más información para procesar y analizar.\n",
    "\"\"\"\n",
    "\n",
    "estadisticas_texto(texto_estadisticas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
