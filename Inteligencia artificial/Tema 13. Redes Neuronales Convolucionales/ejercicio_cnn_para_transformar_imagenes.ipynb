{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9cb8933",
      "metadata": {
        "id": "b9cb8933"
      },
      "source": [
        "# Uso de una red neuronal convolucional para transformar imágenes\n",
        "\n",
        "**Nombre completo del alumno/a**\n",
        "\n",
        "Este cuaderno utiliza el dataset CIFAR-10 y aplica ruido en forma de puntos aleatorios de colores a las imágenes. Entrenaremos un autoencoder para restaurarlas.\n",
        "\n",
        "Las secuencias XXXXXXXXX se deben rellenar con el código apropiado."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "847371b9",
      "metadata": {
        "id": "847371b9"
      },
      "source": [
        "## Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3e189536",
      "metadata": {
        "id": "3e189536"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input\n",
        "\n",
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066ccb9f",
      "metadata": {
        "id": "066ccb9f"
      },
      "source": [
        "## Carga y preparación de Datos\n",
        "Cargamos el dataset CIFAR-10 y añadimos ruido en forma de puntos aleatorios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "yzsRxl-kP38k",
      "metadata": {
        "id": "yzsRxl-kP38k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Carga el dataset CIFAR-10\n",
        "# No es necesario cargar las etiquetas porque vamos a hacer una transformación\n",
        "(x_train, _), (x_test, _) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "UDN7cOk_QBmq",
      "metadata": {
        "id": "UDN7cOk_QBmq"
      },
      "outputs": [],
      "source": [
        "# Normaliza los valores de las imágenes al rango [0, 1]\n",
        "x_train = x_train / 1024\n",
        "x_test = x_test / 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JUbsG944Qlsw",
      "metadata": {
        "id": "JUbsG944Qlsw"
      },
      "outputs": [],
      "source": [
        "# Función que genera ruido en forma de puntos aleatorios a un array de imágenes\n",
        "def add_random_noise(images, num_points):\n",
        "    noisy_images = images.copy()\n",
        "    for img in noisy_images:\n",
        "        height, width, _ = img.shape\n",
        "        for _ in range(num_points):\n",
        "            # Coordenada x\n",
        "            x = np.random.randint(width)\n",
        "            # Coordenada y\n",
        "            y = np.random.randint(height)\n",
        "            # Color aleatorio (RGB)\n",
        "            img[x, y] = np.random.randint(0, 256, 3)\n",
        "    return noisy_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8OU9WLGyRV0E",
      "metadata": {
        "id": "8OU9WLGyRV0E"
      },
      "outputs": [],
      "source": [
        "# Aplica el ruido a los datos (por ej. 300 puntos)\n",
        "x_train_noisy = add_random_noise(x_train, 300)\n",
        "x_test_noisy = add_random_noise(x_test, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "605ca6fc",
      "metadata": {
        "id": "605ca6fc"
      },
      "outputs": [],
      "source": [
        "# Muestra algunas imágenes originales y con ruido\n",
        "n = 5  # Número de imágenes a mostrar\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(n):\n",
        "    # Imagen original\n",
        "    plt.subplot(XXXXXXXXX)\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "\n",
        "    # Imagen con ruido\n",
        "    plt.subplot(XXXXXXXXX)\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee36284",
      "metadata": {
        "id": "4ee36284"
      },
      "source": [
        "## Construcción del Autoencoder\n",
        "Definimos una arquitectura básica de autoencoder para procesar las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc02fbc9",
      "metadata": {
        "id": "bc02fbc9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Construcción del modelo autoencoder\n",
        "model = Sequential([\n",
        "    # Especifica la entrada ajustada para CIFAR-10\n",
        "    # Son imágenes de 32x32 con 3 canales de color\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Se aplica el parámetro padding='same' en todas las capas\n",
        "\n",
        "    # En las capas de convolución, padding='same' hace que\n",
        "    # se mantenga la resolución.\n",
        "\n",
        "    # En las capas de max pooling, se reducen de forma explícita las\n",
        "    # dimensiones de la imagen, aquí padding='same' rellena con ceros los\n",
        "    # bordes cuando la ventana de pooling no encaja perfectamente en la imagen.\n",
        "\n",
        "    # Encoder #####################################################\n",
        "\n",
        "    # Capa de convolución 2D con 32 filtros de convolución de 3x3 y\n",
        "    # ReLU como función de activación\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Capa de max pooling con ventana de 2x2\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Capa de convolución 2D con 32 filtros de convolución de 3x3 y\n",
        "    # ReLU como función de activación\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Capa de max pooling con ventana de 2x2\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Decoder ######################################################\n",
        "\n",
        "    # Capa de convolución 2D con 32 filtros de convolución de 3x3 y\n",
        "    # ReLU como función de activación\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Aumento de resolución (up sampling 2D) para compensar el max pooling\n",
        "    # con una ventana de 2x2.\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Capa de convolución 2D con 32 filtros de convolución de 3x3 y\n",
        "    # ReLU como función de activación\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Aumento de resolución (up sampling 2D) para compensar el max pooling\n",
        "    # con una ventana de 2x2.\n",
        "    XXXXXXXXX,\n",
        "\n",
        "    # Salida restaurada con 3 canales\n",
        "    # Capa de convolución 2D con 3 filtros de convolución de 3x3 y\n",
        "    # sigmoid como función de activación\n",
        "    XXXXXXXXX,\n",
        "])\n",
        "\n",
        "# Compila el modelo con el optimizador adam y la función de pérdida mse\n",
        "XXXXXXXXX\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I9jDw6DpdAHV",
      "metadata": {
        "id": "I9jDw6DpdAHV"
      },
      "outputs": [],
      "source": [
        "# Muestra el resumen del modelo\n",
        "XXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c3a244a",
      "metadata": {
        "id": "7c3a244a"
      },
      "source": [
        "## Entrenamiento del modelo\n",
        "\n",
        "Entrenamos el modelo con las imágenes con ruido como entrada y las originales como objetivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6699c362",
      "metadata": {
        "id": "6699c362"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento del autoencoder\n",
        "# Se entrena el modelo en 10 iteraciones, con un batch size de 128,\n",
        "# con la mezcla (shuffle) activada y especificando los datos de validación.\n",
        "XXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "098aeda3",
      "metadata": {
        "id": "098aeda3"
      },
      "source": [
        "## Evaluación y visualización de resultados\n",
        "\n",
        "Usamos el modelo entrenado para restaurar las imágenes con ruido y comparar los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41425d7a",
      "metadata": {
        "id": "41425d7a"
      },
      "outputs": [],
      "source": [
        "# Usa el modelo para limpiar imágenes con ruido del conjunto de pruebas\n",
        "decoded_images = XXXXXXXXX\n",
        "\n",
        "# Muestra algunas imágenes originales, con ruido y restauradas\n",
        "n = 5  # Número de imágenes a mostrar\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i in range(n):\n",
        "    # Imagen original\n",
        "    plt.subplot(3, n, i + 1)\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "\n",
        "    # Imagen con ruido\n",
        "    plt.subplot(3, n, i + 1 + n)\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "\n",
        "    # Imagen restaurada\n",
        "    plt.subplot(3, n, i + 1 + 2 * n)\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "    XXXXXXXXX\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XcdeVaYkxj6l",
      "metadata": {
        "id": "XcdeVaYkxj6l"
      },
      "source": [
        "## Eliminación de ruido de una imagen externa\n",
        "\n",
        "Cargamos una imagen externa al dataset que tiene ruido para comprobar cómo funciona nuestro autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dSRhDGxyrKg",
      "metadata": {
        "id": "9dSRhDGxyrKg"
      },
      "outputs": [],
      "source": [
        "# Importa las funciones load_img (carga una imagen) y img_to_array (convierte una imagen en un array)\n",
        "XXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Sj7g8dkQzJe1",
      "metadata": {
        "id": "Sj7g8dkQzJe1"
      },
      "outputs": [],
      "source": [
        "# Pide la ruta de la imagen al usuario\n",
        "image_path = XXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "usfIP8qTzQT3",
      "metadata": {
        "id": "usfIP8qTzQT3"
      },
      "outputs": [],
      "source": [
        "# Ajusta la imagen al tamaño esperado por el modelo\n",
        "image = XXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gd0ujcFnzTgY",
      "metadata": {
        "id": "gd0ujcFnzTgY"
      },
      "outputs": [],
      "source": [
        "# Normaliza al rango [0, 1]\n",
        "image_array = XXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pQz_V9dH1ktn",
      "metadata": {
        "id": "pQz_V9dH1ktn"
      },
      "outputs": [],
      "source": [
        "# Expande en una dimensión para indicar el batch size\n",
        "# Se indica la imagen cuyas dimensiones se van a expandir y el eje (axis=0)\n",
        "# Si antes, la imagen tenía las dimensiones (32, 32, 3), después de expandir\n",
        "# las dimensiones, debería tener (1, 32, 32, 3) porque se va a procesar una\n",
        "# sola imagen.\n",
        "image_array = np.XXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0k9XCofW1y-g",
      "metadata": {
        "id": "0k9XCofW1y-g"
      },
      "outputs": [],
      "source": [
        "# Pasa la imagen por el modelo para que le quite el ruido\n",
        "restored_image = XXXXXXXXX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3AiqXuw_ZuE6",
      "metadata": {
        "id": "3AiqXuw_ZuE6"
      },
      "outputs": [],
      "source": [
        "# Muestra las imágenes con ruido y restaurada\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Imagen con ruido\n",
        "plt.subplot(XXXXXXXXX)\n",
        "XXXXXXXXX\n",
        "XXXXXXXXX\n",
        "XXXXXXXXX\n",
        "\n",
        "# Imagen restaurada\n",
        "plt.subplot(XXXXXXXXX)\n",
        "XXXXXXXXX\n",
        "XXXXXXXXX\n",
        "XXXXXXXXX\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6265a81",
      "metadata": {
        "id": "a6265a81"
      },
      "source": [
        "## Conclusiones\n",
        "\n",
        "En este ejemplo, hemos utilizado el dataset CIFAR-10 para entrenar un autoencoder que elimina ruido de imágenes en forma de puntos aleatorios. Puedes experimentar con diferentes arquitecturas, niveles de ruido y datasets para mejorar los resultados."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
